#!/usr/bin/env python3
"""
PHM-Vibench å…¨é¢æ¨¡å—æµ‹è¯•ç¨‹åº

ç»Ÿä¸€æµ‹è¯•æ‰€æœ‰PHM-Vibenchæ¨¡å—çš„åŠŸèƒ½å®Œæ•´æ€§ï¼ŒåŒ…æ‹¬ï¼š
- Model Factory: æ‰€æœ‰æ¨¡å‹ç±»åˆ«çš„åŠŸèƒ½æµ‹è¯•
- Data Factory: æ•°æ®åŠ è½½å’Œå¤„ç†æµ‹è¯•
- Task Factory: ä»»åŠ¡å®šä¹‰å’Œæ‰§è¡Œæµ‹è¯•
- ISFMç³»åˆ—: å®Œæ•´çš„ISFMæ¨¡å‹æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    python test_all_modules.py                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python test_all_modules.py --model           # ä»…æµ‹è¯•æ¨¡å‹å·¥å‚
    python test_all_modules.py --data            # ä»…æµ‹è¯•æ•°æ®å·¥å‚
    python test_all_modules.py --task            # ä»…æµ‹è¯•ä»»åŠ¡å·¥å‚
    python test_all_modules.py --isfm            # ä»…æµ‹è¯•ISFMç³»åˆ—
    python test_all_modules.py --quick           # å¿«é€Ÿæ¨¡å¼ï¼ˆä»…åˆå§‹åŒ–å’Œå‰å‘ï¼‰
    python test_all_modules.py --category cnn    # æµ‹è¯•ç‰¹å®šç±»åˆ«

Author: PHM-Vibench Team
Date: 2025-01-22
"""

import argparse
import os
import sys
import time
import torch
import traceback
from pathlib import Path
from types import SimpleNamespace
from typing import Dict, List, Optional, Tuple, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)


class ModuleTester:
    """ç»Ÿä¸€æ¨¡å—æµ‹è¯•å™¨"""

    def __init__(self, quick_mode=False, verbose=False):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.quick_mode = quick_mode
        self.verbose = verbose

        print(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {self.device}")
        if self.quick_mode:
            print("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šä»…æµ‹è¯•åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­")
        print()

        # æµ‹è¯•ç»Ÿè®¡
        self.stats = {
            'total': 0,
            'passed': 0,
            'failed': 0,
            'skipped': 0,
            'errors': []
        }

    # ==================== Model Factory Tests ====================

    def test_model_factory(self, category=None):
        """æµ‹è¯•Model Factory"""
        print("="*60)
        print("æµ‹è¯• Model Factory")
        print("="*60)

        # æ¨¡å‹é…ç½®æ˜ å°„
        model_configs = self._get_model_configs()

        if category:
            if category.lower() not in model_configs:
                print(f"âŒ æœªçŸ¥ç±»åˆ«: {category}")
                print(f"å¯ç”¨ç±»åˆ«: {list(model_configs.keys())}")
                return False
            model_configs = {category: model_configs[category]}

        results = []
        for cat_name, models in model_configs.items():
            print(f"\n--- {cat_name.upper()} ç³»åˆ—æ¨¡å‹ ---")
            cat_results = self._test_model_category(models, cat_name)
            results.extend(cat_results)

        # æ±‡æ€»ç»“æœ
        passed = sum(1 for r in results if r['status'] == 'passed')
        total = len(results)
        print(f"\næ¨¡å‹å·¥å‚æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

        return passed == total

    def _get_model_configs(self):
        """è·å–æ‰€æœ‰æ¨¡å‹çš„æµ‹è¯•é…ç½®"""
        return {
            'isfm': {
                'M_01_ISFM': {
                    'module': 'src.model_factory.ISFM.M_01_ISFM',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,  # å°æ¨¡å‹ç”¨äºå¿«é€Ÿæµ‹è¯•
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,  # å°è¾“å…¥
                        'num_classes': 3
                    }
                },
                'M_02_ISFM': {
                    'module': 'src.model_factory.ISFM.M_02_ISFM',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'num_classes': 3
                    }
                },
                'M_03_ISFM': {
                    'module': 'src.model_factory.ISFM.M_03_ISFM',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'num_classes': 3
                    }
                },
                'M_02_ISFM_Prompt': {
                    'module': 'src.model_factory.ISFM_Prompt.M_02_ISFM_Prompt',
                    'config': {
                        'embedding': 'E_01_HSE_v2',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'num_classes': {'0': 3},
                        'use_prompt': False,  # ç®€åŒ–æµ‹è¯•
                        'use_prompt_library': False
                    }
                }
            },
            'cnn': {
                'ResNet1D': {
                    'module': 'src.model_factory.CNN.ResNet1D',
                    'config': {
                        'in_channels': 1,
                        'base_filters': 16,  # å°æ¨¡å‹
                        'layers': [1, 1, 1],  # æµ…å±‚ç½‘ç»œ
                        'num_classes': 3
                    }
                },
                'AttentionCNN': {
                    'module': 'src.model_factory.CNN.AttentionCNN',
                    'config': {
                        'in_channels': 1,
                        'num_filters': 16,
                        'kernel_sizes': [3, 5, 7],
                        'num_classes': 3
                    }
                },
                'TCN': {
                    'module': 'src.model_factory.CNN.TCN',
                    'config': {
                        'input_size': 1,
                        'num_channels': [16, 32, 16],
                        'kernel_size': 3,
                        'num_classes': 3
                    }
                }
            },
            'rnn': {
                'AttentionLSTM': {
                    'module': 'src.model_factory.RNN.AttentionLSTM',
                    'config': {
                        'input_size': 1,
                        'hidden_size': 32,
                        'num_layers': 1,
                        'num_classes': 3
                    }
                },
                'AttentionGRU': {
                    'module': 'src.model_factory.RNN.AttentionGRU',
                    'config': {
                        'input_size': 1,
                        'hidden_size': 32,
                        'num_layers': 1,
                        'num_classes': 3
                    }
                }
            },
            'transformer': {
                'PatchTST': {
                    'module': 'src.model_factory.Transformer.PatchTST',
                    'config': {
                        'enc_in': 1,
                        'seq_len': 512,
                        'pred_len': 96,
                        'e_layers': 2,
                        'n_heads': 4,
                        'd_model': 64,
                        'd_ff': 128,
                        'dropout': 0.1,
                        'num_class': 3
                    }
                },
                'Informer': {
                    'module': 'src.model_factory.Transformer.Informer',
                    'config': {
                        'enc_in': 1,
                        'dec_in': 1,
                        'c_out': 3,
                        'seq_len': 512,
                        'label_len': 48,
                        'pred_len': 96,
                        'e_layers': 2,
                        'd_layers': 1,
                        'n_heads': 4,
                        'd_model': 64,
                        'd_ff': 128
                    }
                }
            },
            'mlp': {
                'Dlinear': {
                    'module': 'src.model_factory.MLP.Dlinear',
                    'config': {
                        'individual': False,
                        'seq_len': 512,
                        'enc_in': 1
                    }
                },
                'MLPMixer': {
                    'module': 'src.model_factory.MLP.MLPMixer',
                    'config': {
                        'seq_len': 512,
                        'num_features': 1,
                        'num_classes': 3,
                        'patch_size': 16,
                        'hidden_dim': 64,
                        'num_layers': 2
                    }
                }
            },
            'no': {
                'FNO': {
                    'module': 'src.model_factory.NO.FNO',
                    'config': {
                        'modes': 8,
                        'width': 16,
                        'in_dim': 1,
                        'out_dim': 3
                    }
                }
            }
        }

    def _test_model_category(self, models: Dict, category: str) -> List[Dict]:
        """æµ‹è¯•ç‰¹å®šç±»åˆ«çš„æ¨¡å‹"""
        results = []

        for model_name, model_info in models.items():
            result = self._test_single_model(model_name, model_info, category)
            results.append(result)

            # æ‰“å°ç»“æœ
            status_icon = "âœ“" if result['status'] == 'passed' else "âœ—"
            params_info = f", {result['params']:,}å‚æ•°" if result['params'] else ""
            print(f"  {status_icon} {model_name}: {result['message']}{params_info}")

            if result['error'] and self.verbose:
                print(f"    é”™è¯¯: {result['error']}")

        return results

    def _test_single_model(self, model_name: str, model_info: Dict, category: str) -> Dict:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        result = {
            'name': model_name,
            'category': category,
            'status': 'failed',
            'params': 0,
            'message': '',
            'error': None
        }

        try:
            # åŠ¨æ€å¯¼å…¥
            module_path = model_info['module']
            module_name = module_path.split('.')[-1]

            # ç‰¹æ®Šå¤„ç†ISFMæ¨¡å‹
            if category == 'isfm':
                return self._test_isfm_model(model_name, model_info, category)

            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(**model_info['config'])

            # å¯¼å…¥æ¨¡å‹
            if category == 'mlp' and model_name == 'Dlinear':
                # Dlinearç‰¹æ®Šå¤„ç†
                from src.model_factory.MLP.Dlinear import Model
                model = Model(config).to(self.device)
            else:
                # åŠ¨æ€å¯¼å…¥
                module = __import__(module_path, fromlist=['Model'])
                Model = getattr(module, 'Model')
                model = Model(config).to(self.device)

            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            result['params'] = total_params

            # æµ‹è¯•æ•°æ®
            test_input = self._get_test_input(category, config)

            # å‰å‘ä¼ æ’­æµ‹è¯•
            model.eval()
            with torch.no_grad():
                if category == 'transformer':
                    # Transformeræ¨¡å‹é€šå¸¸éœ€è¦é¢å¤–çš„è¾“å…¥
                    if 'Informer' in model_name:
                        output = model(test_input['x'], test_input['x_mark'], test_input['dec_inp'])
                    else:
                        output = model(test_input)
                else:
                    output = model(test_input)

            result['status'] = 'passed'
            result['message'] = 'åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­æˆåŠŸ'

            # éå¿«é€Ÿæ¨¡å¼ï¼šæµ‹è¯•æ¢¯åº¦
            if not self.quick_mode:
                model.train()
                output = model(test_input)
                if isinstance(output, (list, tuple)):
                    output = output[0]

                # åˆ›å»ºè™šæ‹ŸæŸå¤±
                if output.dim() == 3:
                    output = output.mean(dim=(1, 2))
                elif output.dim() == 2:
                    output = output.mean(dim=1)

                loss = output.sum()
                loss.backward()

                # æ£€æŸ¥æ¢¯åº¦
                has_grad = any(p.grad is not None for p in model.parameters())
                if has_grad:
                    result['message'] += ' + æ¢¯åº¦æ£€æŸ¥é€šè¿‡'

        except Exception as e:
            result['error'] = str(e)
            result['message'] = f'æµ‹è¯•å¤±è´¥'

            # ç®€åŒ–é”™è¯¯æ¶ˆæ¯
            if 'CUDA out of memory' in str(e):
                result['message'] = 'GPUå†…å­˜ä¸è¶³'
            elif 'No module named' in str(e):
                result['message'] = 'æ¨¡å—ç¼ºå¤±'
                result['status'] = 'skipped'

        return result

    def _test_isfm_model(self, model_name: str, model_info: Dict, category: str) -> Dict:
        """æµ‹è¯•ISFMç³»åˆ—æ¨¡å‹"""
        result = {
            'name': model_name,
            'category': category,
            'status': 'failed',
            'params': 0,
            'message': '',
            'error': None
        }

        try:
            # åˆ›å»ºmock metadata
            class MockMetadata:
                def __getitem__(self, idx):
                    return {
                        'Sample_rate': 12000,
                        'Dataset_id': '0',
                        'Domain_id': '0',
                        'Label': 0
                    }

            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(**model_info['config'])

            # å¯¼å…¥ISFMæ¨¡å‹
            if 'Prompt' in model_name:
                from src.model_factory.ISFM_Prompt.M_02_ISFM_Prompt import Model
                # æ·»åŠ ç¼ºå¤±çš„é…ç½®
                config.prompt_dim = 64
                config.fusion_type = 'concat'
                config.selection_mode = 'soft'
                config.temperature = 1.0
                config.training_stage = 'pretrain'
                config.output_dim = 128
                config.seq_len = config.input_len
                config.patch_size_L = 16
                config.patch_size_C = 1
            else:
                from src.model_factory.ISFM.M_03_ISFM import Model
                config.output_dim = 128
                config.seq_len = config.input_len
                config.patch_size_L = 16
                config.patch_size_C = 1

            # åˆå§‹åŒ–æ¨¡å‹
            model = Model(config, MockMetadata()).to(self.device)
            total_params = sum(p.numel() for p in model.parameters())
            result['params'] = total_params

            # æµ‹è¯•æ•°æ®
            x = torch.randn(4, config.input_len, 1, device=self.device)
            file_ids = ['sample_001', 'sample_002', 'sample_003', 'sample_004']

            # å‰å‘ä¼ æ’­
            model.eval()
            with torch.no_grad():
                if 'Prompt' in model_name:
                    output = model(x, file_ids, task_id='classification')
                else:
                    output = model(x, file_ids, task_id='classification')

            result['status'] = 'passed'
            result['message'] = 'ISFMæ¨¡å‹æµ‹è¯•æˆåŠŸ'

            # éå¿«é€Ÿæ¨¡å¼ï¼šæµ‹è¯•è®­ç»ƒ
            if not self.quick_mode:
                model.train()
                optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
                loss_fn = torch.nn.CrossEntropyLoss()

                output = model(x, file_ids, task_id='classification')
                targets = torch.randint(0, 3, (4,), device=self.device)
                loss = loss_fn(output, targets)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                result['message'] += ' + è®­ç»ƒæµ‹è¯•é€šè¿‡'

        except Exception as e:
            result['error'] = str(e)
            result['message'] = 'ISFMæµ‹è¯•å¤±è´¥'

            if 'CUDA out of memory' in str(e):
                result['message'] = 'GPUå†…å­˜ä¸è¶³'

        return result

    def _get_test_input(self, category: str, config) -> Any:
        """æ ¹æ®æ¨¡å‹ç±»åˆ«ç”Ÿæˆæµ‹è¯•è¾“å…¥"""
        batch_size = 4

        if category == 'cnn' or category == 'rnn':
            # CNN/RNN: (batch, seq_len, features)
            return torch.randn(batch_size, 512, 1, device=self.device)

        elif category == 'transformer':
            # Transformer: ç‰¹æ®Šå¤„ç†
            if 'Informer' in str(config):
                x = torch.randn(batch_size, 512, 1, device=self.device)
                x_mark = torch.randn(batch_size, 512, 4, device=self.device)
                dec_inp = torch.randn(batch_size, 96, 1, device=self.device)
                return {'x': x, 'x_mark': x_mark, 'dec_inp': dec_inp}
            else:
                return torch.randn(batch_size, 1, 512, device=self.device)

        elif category == 'mlp':
            # MLP: (batch, seq_len, features)
            return torch.randn(batch_size, 512, 1, device=self.device)

        elif category == 'no':
            # Neural Operator: (batch, x, y, features)
            return torch.randn(batch_size, 32, 32, 1, device=self.device)

        else:
            # é»˜è®¤
            return torch.randn(batch_size, 512, 1, device=self.device)

    # ==================== Data Factory Tests ====================

    def test_data_factory(self):
        """æµ‹è¯•Data Factory"""
        print("="*60)
        print("æµ‹è¯• Data Factory")
        print("="*60)

        try:
            from src.data_factory import build_data
            print("âœ“ Data Factoryå¯¼å…¥æˆåŠŸ")

            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(
                data_name='CWRU',
                data_dir='./data',
                batch_size=4,
                seq_len=512,
                feature_cols=[0],
                target_cols=[0],
                scale=True,
                task_type='classification'
            )

            # æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆä¼šå¤±è´¥ä½†éªŒè¯äº†æ¨¡å—å­˜åœ¨ï¼‰
            try:
                data_loader = build_data(config)
                print("âœ“ æ•°æ®åŠ è½½å™¨æ„å»ºæˆåŠŸ")
            except Exception as e:
                if 'No such file or directory' in str(e):
                    print("âœ“ æ•°æ®åŠ è½½å™¨æ¨¡å—æ­£å¸¸ï¼ˆæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æ˜¯é¢„æœŸçš„ï¼‰")
                else:
                    raise e

            return True

        except Exception as e:
            print(f"âŒ Data Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    # ==================== Task Factory Tests ====================

    def test_task_factory(self):
        """æµ‹è¯•Task Factory"""
        print("="*60)
        print("æµ‹è¯• Task Factory")
        print("="*60)

        try:
            from src.task_factory import build_task
            print("âœ“ Task Factoryå¯¼å…¥æˆåŠŸ")

            # æµ‹è¯•åˆ†ç±»ä»»åŠ¡
            config = SimpleNamespace(
                task_name='classification',
                num_classes=3,
                loss_weight=1.0
            )

            task = build_task(config)
            print("âœ“ åˆ†ç±»ä»»åŠ¡æ„å»ºæˆåŠŸ")

            # æµ‹è¯•é¢„æµ‹ä»»åŠ¡
            config = SimpleNamespace(
                task_name='prediction',
                pred_len=96,
                loss_weight=1.0
            )

            task = build_task(config)
            print("âœ“ é¢„æµ‹ä»»åŠ¡æ„å»ºæˆåŠŸ")

            return True

        except Exception as e:
            print(f"âŒ Task Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    # ==================== Trainer Factory Tests ====================

    def test_trainer_factory(self):
        """æµ‹è¯•Trainer Factory"""
        print("="*60)
        print("æµ‹è¯• Trainer Factory")
        print("="*60)

        try:
            from src.trainer_factory import build_trainer
            print("âœ“ Trainer Factoryå¯¼å…¥æˆåŠŸ")

            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(
                trainer_name='lightning',
                max_epochs=1,
                learning_rate=1e-3,
                accelerator='auto'
            )

            # æµ‹è¯•è®­ç»ƒå™¨æ„å»ºï¼ˆä¸éœ€è¦å®é™…è¿è¡Œï¼‰
            trainer = build_trainer(config)
            print("âœ“ è®­ç»ƒå™¨æ„å»ºæˆåŠŸ")

            return True

        except Exception as e:
            print(f"âŒ Trainer Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    # ==================== ISFM Series Tests ====================

    def test_isfm_series(self):
        """æµ‹è¯•ISFMç³»åˆ—"""
        print("="*60)
        print("æµ‹è¯• ISFM ç³»åˆ—")
        print("="*60)

        # è¿è¡Œç°æœ‰çš„ISFMæµ‹è¯•
        try:
            from test.test_runner import main as test_runner_main
            print("è¿è¡ŒISFMä¸“é¡¹æµ‹è¯•...")

            # è¿™é‡Œä¸èƒ½ç›´æ¥è°ƒç”¨mainï¼Œå› ä¸ºå®ƒä¼šé€€å‡ºç¨‹åº
            # ä½¿ç”¨æˆ‘ä»¬å·²ç»æµ‹è¯•è¿‡çš„å‡½æ•°
            from test.test_runner import test_m02_isfm, test_m02_isfm_prompt

            results = []
            print("\n--- M_02_ISFM æµ‹è¯• ---")
            if test_m02_isfm():
                results.append(True)
                print("âœ“ M_02_ISFM æµ‹è¯•é€šè¿‡")
            else:
                results.append(False)
                print("âœ— M_02_ISFM æµ‹è¯•å¤±è´¥")

            print("\n--- M_02_ISFM_Prompt æµ‹è¯• ---")
            if test_m02_isfm_prompt():
                results.append(True)
                print("âœ“ M_02_ISFM_Prompt æµ‹è¯•é€šè¿‡")
            else:
                results.append(False)
                print("âœ— M_02_ISFM_Prompt æµ‹è¯•å¤±è´¥")

            return all(results)

        except Exception as e:
            print(f"âŒ ISFMç³»åˆ—æµ‹è¯•å¤±è´¥: {e}")
            return False

    # ==================== Main Test Runner ====================

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        start_time = time.time()

        print("PHM-Vibench å…¨é¢æ¨¡å—æµ‹è¯•")
        print("="*60)
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ¨¡å¼: {'å¿«é€Ÿ' if self.quick_mode else 'å®Œæ•´'}")
        print(f"è¯¦ç»†è¾“å‡º: {'æ˜¯' if self.verbose else 'å¦'}")
        print()

        test_results = {}

        # 1. Model Factoryæµ‹è¯•
        try:
            test_results['model_factory'] = self.test_model_factory()
        except Exception as e:
            print(f"âŒ Model Factoryæµ‹è¯•å¼‚å¸¸: {e}")
            test_results['model_factory'] = False

        # 2. Data Factoryæµ‹è¯•
        try:
            test_results['data_factory'] = self.test_data_factory()
        except Exception as e:
            print(f"âŒ Data Factoryæµ‹è¯•å¼‚å¸¸: {e}")
            test_results['data_factory'] = False

        # 3. Task Factoryæµ‹è¯•
        try:
            test_results['task_factory'] = self.test_task_factory()
        except Exception as e:
            print(f"âŒ Task Factoryæµ‹è¯•å¼‚å¸¸: {e}")
            test_results['task_factory'] = False

        # 4. Trainer Factoryæµ‹è¯•
        try:
            test_results['trainer_factory'] = self.test_trainer_factory()
        except Exception as e:
            print(f"âŒ Trainer Factoryæµ‹è¯•å¼‚å¸¸: {e}")
            test_results['trainer_factory'] = False

        # 5. ISFMç³»åˆ—æµ‹è¯•
        try:
            test_results['isfm_series'] = self.test_isfm_series()
        except Exception as e:
            print(f"âŒ ISFMç³»åˆ—æµ‹è¯•å¼‚å¸¸: {e}")
            test_results['isfm_series'] = False

        # æ€»ç»“
        elapsed = time.time() - start_time
        self._print_summary(test_results, elapsed)

        return all(test_results.values())

    def _print_summary(self, results: Dict[str, bool], elapsed: float):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*60)
        print("æµ‹è¯•æ€»ç»“")
        print("="*60)

        for test_name, passed in results.items():
            status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
            display_name = {
                'model_factory': 'Model Factory',
                'data_factory': 'Data Factory',
                'task_factory': 'Task Factory',
                'trainer_factory': 'Trainer Factory',
                'isfm_series': 'ISFMç³»åˆ—'
            }.get(test_name, test_name)
            print(f"{display_name}: {status}")

        total_passed = sum(results.values())
        total_tests = len(results)

        print(f"\næ€»ä½“ç»“æœ: {total_passed}/{total_tests} æµ‹è¯•å¥—ä»¶é€šè¿‡")
        print(f"æ€»è€—æ—¶: {elapsed//60:.0f}åˆ†{elapsed%60:.0f}ç§’")

        if total_passed == total_tests:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼PHM-Vibenchæ¨¡å—åŠŸèƒ½æ­£å¸¸ã€‚")
        else:
            print(f"\nâš ï¸ {total_tests - total_passed}ä¸ªæµ‹è¯•å¥—ä»¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ã€‚")
            if self.verbose:
                print("\nä½¿ç”¨ --verbose æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PHM-Vibenchå…¨é¢æ¨¡å—æµ‹è¯•')
    parser.add_argument('--model', action='store_true', help='ä»…æµ‹è¯•Model Factory')
    parser.add_argument('--data', action='store_true', help='ä»…æµ‹è¯•Data Factory')
    parser.add_argument('--task', action='store_true', help='ä»…æµ‹è¯•Task Factory')
    parser.add_argument('--trainer', action='store_true', help='ä»…æµ‹è¯•Trainer Factory')
    parser.add_argument('--isfm', action='store_true', help='ä»…æµ‹è¯•ISFMç³»åˆ—')
    parser.add_argument('--category', help='æµ‹è¯•ç‰¹å®šæ¨¡å‹ç±»åˆ« (cnn/rnn/transformer/mlp/no/isfm)')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆä»…åˆå§‹åŒ–å’Œå‰å‘ï¼‰')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')

    args = parser.parse_args()

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ModuleTester(quick_mode=args.quick, verbose=args.verbose)

    # æ ¹æ®å‚æ•°è¿è¡Œæµ‹è¯•
    success = True

    if args.model:
        success = tester.test_model_factory(args.category)
    elif args.data:
        success = tester.test_data_factory()
    elif args.task:
        success = tester.test_task_factory()
    elif args.trainer:
        success = tester.test_trainer_factory()
    elif args.isfm:
        success = tester.test_isfm_series()
    else:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        success = tester.run_all_tests()

    # é€€å‡º
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()