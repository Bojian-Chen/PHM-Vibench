# Unified Metric Learning 1-Epoch Test Configuration
# Quick validation configuration for testing pipeline functionality
# Following PHM-Vibench standard structure

# Environment Configuration
environment:
  VBENCH_HOME: "/home/lq/LQcode/2_project/PHMBench/PHM-Vibench"
  project: "Unified_Metric_Learning_1Epoch_Test"
  seed: 42
  output_dir: "results/unified_metric_learning_1epoch"
  notes: "1-epoch validation test for pipeline functionality"
  iterations: 1

# Data Configuration
data:
  data_dir: "/mnt/crucial/LQ/PHM-Vibench"
  metadata_file: "metadata_6_11.xlsx"

  # Data preprocessing - simplified for quick testing
  batch_size: 16
  num_workers: 4
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  normalization: "standardization"
  window_size: 2048
  stride: 10
  num_window: 32
  dtype: "float32"
  pin_memory: true

  # Quick test settings
  max_samples_per_class: 100

# Model Configuration - ISFM Foundation Model
model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"

  # Architecture components
  embedding: "E_01_HSE_v2"
  backbone: "B_08_PatchTST"
  task_head: "H_01_Linear_cla"

  # Model dimensions
  input_dim: 1
  d_model: 128
  output_dim: 64

  # Transformer settings (reduced for fast testing)
  num_heads: 4
  num_layers: 2
  e_layers: 2
  d_ff: 256
  dropout: 0.1
  activation: "relu"
  factor: 5

  # Patch settings
  patch_size_L: 16
  patch_size_C: 1
  num_patches: 64

  gradient_checkpointing: false
  mixed_precision: false
  use_prompt: true
  prompt_dim: 64
  fusion_type: "attention"
  training_stage: "pretrain"
  freeze_prompt: false

# Task Configuration
task:
  name: "hse_contrastive"
  type: "CDDG"

  # Single dataset for initial test
  target_system_id: [1]  # CWRU only for initial test
  target_domain_num: 5

  # HSE Contrastive Learning Parameters
  contrast_loss: "INFONCE"
  contrast_weight: 0.15
  temperature: 0.07
  use_momentum: true
  momentum: 0.999
  projection_dim: 64
  prompt_weight: 0.1
  use_system_sampling: true
  cross_system_contrast: true

  # Training hyperparameters - 1 epoch
  loss: "CE"
  metrics: ["acc", "f1"]
  optimizer: "adamw"
  lr: 0.001
  weight_decay: 0.001
  epochs: 1
  early_stopping: false
  scheduler: false
  wandb: false

  # Required fields for task factory
  gpus: 1
  monitor: "val_loss"

# Trainer Configuration
trainer:
  name: "Default_trainer"

  # Required trainer fields
  num_epochs: 1
  gpus: 1
  device: "cuda"
  monitor: "val_loss"
  pruning: false

  # Performance settings
  log_every_n_steps: 10
  early_stopping: false
  wandb: false