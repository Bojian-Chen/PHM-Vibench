{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加到 data_factory.py 文件中\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class IDSelector:\n",
    "    \"\"\"数据ID选择器基类\n",
    "    \n",
    "    负责根据不同的选择策略和任务要求，选择适当的训练/测试ID\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metadata, args_task):\n",
    "        \"\"\"\n",
    "        初始化ID选择器\n",
    "        \n",
    "        参数:\n",
    "            metadata: 元数据对象\n",
    "            args_task: 任务配置参数\n",
    "        \"\"\"\n",
    "        self.metadata = metadata\n",
    "        self.args_task = args_task\n",
    "        self.train_val_ids = []\n",
    "        self.test_ids = []\n",
    "        self._split_cache = None\n",
    "        \n",
    "    def select(self):\n",
    "        \"\"\"\n",
    "        执行ID选择，确定训练/验证和测试数据集的ID\n",
    "        \n",
    "        返回:\n",
    "            tuple: (train_val_ids, test_ids) 训练/验证ID列表和测试ID列表\n",
    "        \"\"\"\n",
    "        # 检查缓存\n",
    "        cache_id = self._get_cache_id()\n",
    "        if self._split_cache and self._split_cache.get('id') == cache_id:\n",
    "            print(f\"使用缓存的ID选择结果\")\n",
    "            return self._split_cache['train_val_ids'], self._split_cache['test_ids']\n",
    "        \n",
    "        # 如果未指定目标数据集，返回所有ID\n",
    "        if not hasattr(self.args_task, 'target_dataset_id') or self.args_task.target_dataset_id is None:\n",
    "            self.train_val_ids = list(self.metadata.keys())\n",
    "            self.test_ids = list(self.metadata.keys())\n",
    "            print(f\"未指定目标数据集ID，使用全部 {len(self.train_val_ids)} 个样本\")\n",
    "            return self.train_val_ids, self.test_ids\n",
    "        \n",
    "        # 选择ID\n",
    "        self._select_ids()\n",
    "        \n",
    "        # 打印选择统计信息\n",
    "        self._print_stats()\n",
    "        \n",
    "        # 缓存结果\n",
    "        self._split_cache = {\n",
    "            'id': cache_id,\n",
    "            'train_val_ids': self.train_val_ids,\n",
    "            'test_ids': self.test_ids\n",
    "        }\n",
    "        \n",
    "        return self.train_val_ids, self.test_ids\n",
    "    \n",
    "    def _get_cache_id(self):\n",
    "        \"\"\"生成缓存ID\"\"\"\n",
    "        import hashlib\n",
    "        # 将关键参数转换为字符串并哈希\n",
    "        params = {\n",
    "            'target_dataset_id': getattr(self.args_task, 'target_dataset_id', None),\n",
    "            'type': getattr(self.args_task, 'type', None),\n",
    "            'selector': getattr(self.args_task, 'selector', 'default'),\n",
    "            'seed': getattr(self.args_task, 'seed', 42)\n",
    "        }\n",
    "        \n",
    "        # 添加子类特定参数\n",
    "        extra_params = self._get_extra_params()\n",
    "        params.update(extra_params)\n",
    "        \n",
    "        return hashlib.md5(str(params).encode()).hexdigest()\n",
    "    \n",
    "    def _get_extra_params(self):\n",
    "        \"\"\"获取子类特定的缓存参数，由子类实现\"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def _select_ids(self):\n",
    "        \"\"\"执行ID选择，由子类实现\"\"\"\n",
    "        raise NotImplementedError(\"子类必须实现_select_ids方法\")\n",
    "    \n",
    "    def _print_stats(self):\n",
    "        \"\"\"打印ID选择统计信息\"\"\"\n",
    "        if not hasattr(self, 'train_val_ids') or not hasattr(self, 'test_ids'):\n",
    "            return\n",
    "        \n",
    "        # 统计每个数据集的样本数量\n",
    "        train_stats = self._get_dataset_stats(self.train_val_ids)\n",
    "        test_stats = self._get_dataset_stats(self.test_ids)\n",
    "        \n",
    "        print(\"\\n数据选择结果统计:\")\n",
    "        print(f\"总训练/验证样本数: {len(self.train_val_ids)}\")\n",
    "        print(f\"总测试样本数: {len(self.test_ids)}\")\n",
    "        \n",
    "        if train_stats:\n",
    "            print(\"\\n各数据集样本分布:\")\n",
    "            for dataset_id in sorted(set(list(train_stats.keys()) + list(test_stats.keys()))):\n",
    "                train_count = train_stats.get(dataset_id, {'count': 0})['count']\n",
    "                test_count = test_stats.get(dataset_id, {'count': 0})['count']\n",
    "                total = train_count + test_count\n",
    "                print(f\"  数据集 {dataset_id}: 训练={train_count} ({train_count/total:.1%}), 测试={test_count} ({test_count/total:.1%})\")\n",
    "    \n",
    "    def _get_dataset_stats(self, id_list):\n",
    "        \"\"\"获取指定ID列表的数据集统计信息\"\"\"\n",
    "        stats = {}\n",
    "        for id in id_list:\n",
    "            try:\n",
    "                dataset_id = self.metadata.df.loc[id, 'Dataset_id']\n",
    "                if dataset_id not in stats:\n",
    "                    stats[dataset_id] = {'count': 0, 'labels': {}}\n",
    "                \n",
    "                stats[dataset_id]['count'] += 1\n",
    "                \n",
    "                # 如果有标签信息，统计标签分布\n",
    "                if 'Label' in self.metadata.df.columns:\n",
    "                    label = self.metadata.df.loc[id, 'Label']\n",
    "                    if label not in stats[dataset_id]['labels']:\n",
    "                        stats[dataset_id]['labels'][label] = 0\n",
    "                    stats[dataset_id]['labels'][label] += 1\n",
    "            except:\n",
    "                # 处理ID不存在的情况\n",
    "                continue\n",
    "                \n",
    "        return stats\n",
    "    \n",
    "    def visualize(self, save_path=None):\n",
    "        \"\"\"可视化ID选择结果\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            import numpy as np\n",
    "            import pandas as pd\n",
    "            \n",
    "            # 准备数据\n",
    "            data = []\n",
    "            \n",
    "            # 处理所有ID\n",
    "            for id in self.train_val_ids:\n",
    "                try:\n",
    "                    row = self.metadata.df.loc[id]\n",
    "                    data.append({\n",
    "                        'Dataset': row['Dataset_id'],\n",
    "                        'Domain': row['Domain_id'] if 'Domain_id' in row else 'Unknown',\n",
    "                        'Split': 'Train',\n",
    "                        'Label': row['Label'] if 'Label' in row else 'Unknown'\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            for id in self.test_ids:\n",
    "                try:\n",
    "                    row = self.metadata.df.loc[id]\n",
    "                    data.append({\n",
    "                        'Dataset': row['Dataset_id'],\n",
    "                        'Domain': row['Domain_id'] if 'Domain_id' in row else 'Unknown',\n",
    "                        'Split': 'Test',\n",
    "                        'Label': row['Label'] if 'Label' in row else 'Unknown'\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if not data:\n",
    "                print(\"没有足够的数据进行可视化\")\n",
    "                return\n",
    "                \n",
    "            # 创建DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # 创建可视化图表\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.countplot(data=df, x='Dataset', hue='Split', palette='Set2')\n",
    "            plt.title('数据集分布')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if save_path:\n",
    "                plt.savefig(f\"{save_path}_datasets.png\")\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "            \n",
    "            # 如果有标签信息，绘制标签分布\n",
    "            if 'Label' in df.columns and df['Label'].nunique() > 1:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                sns.countplot(data=df, x='Label', hue='Split', palette='Set3')\n",
    "                plt.title('标签分布')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                if save_path:\n",
    "                    plt.savefig(f\"{save_path}_labels.png\")\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"可视化数据时出错: {e}\")\n",
    "\n",
    "\n",
    "class DGIDSelector(IDSelector):\n",
    "    \"\"\"领域泛化ID选择器\"\"\"\n",
    "    \n",
    "    def _get_extra_params(self):\n",
    "        \"\"\"获取领域泛化特定参数\"\"\"\n",
    "        return {\n",
    "            'source_domain_id': getattr(self.args_task, 'source_domain_id', None),\n",
    "            'target_domain_id': getattr(self.args_task, 'target_domain_id', None),\n",
    "            'target_domain_num': getattr(self.args_task, 'target_domain_num', 1)\n",
    "        }\n",
    "    \n",
    "    def _select_ids(self):\n",
    "        \"\"\"领域泛化ID选择\"\"\"\n",
    "        task_type = getattr(self.args_task, 'type', 'DG')\n",
    "        \n",
    "        if task_type == 'DG':\n",
    "            self._select_dg()\n",
    "        elif task_type == 'CDDG':\n",
    "            self._select_cddg()\n",
    "        elif task_type == 'CDGD':\n",
    "            self._select_cdgd()\n",
    "        else:\n",
    "            print(f\"未知的任务类型: {task_type}，使用默认DG选择\")\n",
    "            self._select_dg()\n",
    "    \n",
    "    def _select_dg(self):\n",
    "        \"\"\"标准领域泛化选择\"\"\"\n",
    "        # 过滤数据集\n",
    "        filtered_df = self.metadata.df[\n",
    "            self.metadata.df['Dataset_id'].isin(self.args_task.target_dataset_id)]\n",
    "        \n",
    "        # 训练域\n",
    "        train_df = filtered_df[\n",
    "            filtered_df['Domain_id'].isin(self.args_task.source_domain_id)]\n",
    "        \n",
    "        # 测试域\n",
    "        test_df = filtered_df[\n",
    "            filtered_df['Domain_id'].isin(self.args_task.target_domain_id)]\n",
    "        \n",
    "        self.train_val_ids = list(train_df['Id'])\n",
    "        self.test_ids = list(test_df['Id'])\n",
    "        \n",
    "        print(f\"DG选择 - 源域: {self.args_task.source_domain_id}, 目标域: {self.args_task.target_domain_id}\")\n",
    "    \n",
    "    def _select_cddg(self):\n",
    "        \"\"\"跨数据集领域泛化选择\"\"\"\n",
    "        # 筛选出目标数据集\n",
    "        filtered_df = self.metadata.df[\n",
    "            self.metadata.df['Dataset_id'].isin(self.args_task.target_dataset_id)]\n",
    "        \n",
    "        # 找出每个数据集的域\n",
    "        dataset_domains = {}\n",
    "        for dataset_id in self.args_task.target_dataset_id:\n",
    "            dataset_df = filtered_df[filtered_df['Dataset_id'] == dataset_id]\n",
    "            domains = sorted(dataset_df['Domain_id'].unique())\n",
    "            domains = [d for d in domains if not pd.isna(d)]\n",
    "            dataset_domains[dataset_id] = domains\n",
    "        \n",
    "        # 为每个数据集选择训练和测试域\n",
    "        train_domains = {}\n",
    "        test_domains = {}\n",
    "        for dataset_id, domains in dataset_domains.items():\n",
    "            test_count = min(self.args_task.target_domain_num, len(domains))\n",
    "            train_domains[dataset_id] = domains[:-test_count] if test_count > 0 else domains\n",
    "            test_domains[dataset_id] = domains[-test_count:] if test_count > 0 else []\n",
    "        \n",
    "        # 收集ID\n",
    "        train_rows = []\n",
    "        test_rows = []\n",
    "        for dataset_id in self.args_task.target_dataset_id:\n",
    "            # 训练集\n",
    "            for domain_id in train_domains[dataset_id]:\n",
    "                train_rows.extend(\n",
    "                    filtered_df[(filtered_df['Dataset_id'] == dataset_id) & \n",
    "                             (filtered_df['Domain_id'] == domain_id)]['Id'].tolist()\n",
    "                )\n",
    "            # 测试集\n",
    "            for domain_id in test_domains[dataset_id]:\n",
    "                test_rows.extend(\n",
    "                    filtered_df[(filtered_df['Dataset_id'] == dataset_id) & \n",
    "                             (filtered_df['Domain_id'] == domain_id)]['Id'].tolist()\n",
    "                )\n",
    "        \n",
    "        self.train_val_ids = train_rows\n",
    "        self.test_ids = test_rows\n",
    "        \n",
    "        # 打印信息\n",
    "        print(f\"CDDG选择 - 每个数据集使用最后{self.args_task.target_domain_num}个域作为测试\")\n",
    "        for dataset_id in self.args_task.target_dataset_id:\n",
    "            print(f\"  数据集 {dataset_id}:\")\n",
    "            print(f\"    训练域: {train_domains[dataset_id]}\")\n",
    "            print(f\"    测试域: {test_domains[dataset_id]}\")\n",
    "    \n",
    "    def _select_cdgd(self):\n",
    "        \"\"\"自定义领域泛化选择\"\"\"\n",
    "        # 类似于_select_cddg的实现...\n",
    "        filtered_df = self.metadata.df[\n",
    "            self.metadata.df['Dataset_id'].isin(self.args_task.target_dataset_id)]\n",
    "        \n",
    "        # 构建分组和ID选择...\n",
    "        group_by = getattr(self.args_task, 'group_by', 'Domain_id')\n",
    "        print(f\"CDGD选择 - 按 {group_by} 分组\")\n",
    "        \n",
    "        train_rows = []\n",
    "        test_rows = []\n",
    "        # 实现分组选择逻辑...\n",
    "        \n",
    "        self.train_val_ids = train_rows\n",
    "        self.test_ids = test_rows\n",
    "\n",
    "\n",
    "class FewShotIDSelector(IDSelector):\n",
    "    \"\"\"小样本学习ID选择器\"\"\"\n",
    "    \n",
    "    def _get_extra_params(self):\n",
    "        \"\"\"获取小样本学习特定参数\"\"\"\n",
    "        return {\n",
    "            'n_way': getattr(self.args_task, 'n_way', 5),\n",
    "            'k_shot': getattr(self.args_task, 'k_shot', 1),\n",
    "            'n_query': getattr(self.args_task, 'n_query', 15),\n",
    "            'test_ratio': getattr(self.args_task, 'test_ratio', 0.2),\n",
    "            'balanced': getattr(self.args_task, 'balanced', True)\n",
    "        }\n",
    "    \n",
    "    def _select_ids(self):\n",
    "        \"\"\"小样本学习ID选择\"\"\"\n",
    "        # 过滤数据集\n",
    "        filtered_df = self.metadata.df[\n",
    "            self.metadata.df['Dataset_id'].isin(self.args_task.target_dataset_id)]\n",
    "        \n",
    "        # 设置随机种子\n",
    "        random.seed(getattr(self.args_task, 'seed', 42))\n",
    "        \n",
    "        # 检查标签列\n",
    "        label_col = getattr(self.args_task, 'label_column', 'Label')\n",
    "        if label_col not in filtered_df.columns:\n",
    "            print(f\"警告: 找不到标签列 '{label_col}'，无法执行小样本采样\")\n",
    "            # 回退到随机选择\n",
    "            self._random_select(filtered_df)\n",
    "            return\n",
    "        \n",
    "        # 获取所有可用类别\n",
    "        all_classes = sorted(filtered_df[label_col].unique())\n",
    "        all_classes = [c for c in all_classes if not pd.isna(c)]\n",
    "        \n",
    "        # n-way k-shot设置\n",
    "        n_way = min(getattr(self.args_task, 'n_way', 5), len(all_classes))\n",
    "        k_shot = getattr(self.args_task, 'k_shot', 1)\n",
    "        n_query = getattr(self.args_task, 'n_query', 15)\n",
    "        \n",
    "        # 随机选择n_way个类别\n",
    "        selected_classes = random.sample(all_classes, n_way)\n",
    "        \n",
    "        print(f\"Few-Shot采样 - {n_way}-way {k_shot}-shot\")\n",
    "        print(f\"  选择的类别: {selected_classes}\")\n",
    "        \n",
    "        # 收集支持集和查询集样本\n",
    "        support_ids = []\n",
    "        query_ids = []\n",
    "        \n",
    "        for cls in selected_classes:\n",
    "            # 获取当前类别的所有样本\n",
    "            cls_samples = filtered_df[filtered_df[label_col] == cls]['Id'].tolist()\n",
    "            \n",
    "            if len(cls_samples) <= k_shot:\n",
    "                # 类别样本不足\n",
    "                print(f\"  警告: 类别 {cls} 的样本数量 ({len(cls_samples)}) 小于 k_shot ({k_shot})\")\n",
    "                support_ids.extend(cls_samples)\n",
    "                continue\n",
    "                \n",
    "            # 随机选择k_shot个样本作为支持集\n",
    "            cls_support = random.sample(cls_samples, k_shot)\n",
    "            support_ids.extend(cls_support)\n",
    "            \n",
    "            # 剩余样本作为查询集\n",
    "            cls_query = [s for s in cls_samples if s not in cls_support]\n",
    "            # 如果指定了查询样本数量，随机选择n_query个\n",
    "            if n_query > 0 and len(cls_query) > n_query:\n",
    "                cls_query = random.sample(cls_query, n_query)\n",
    "            \n",
    "            query_ids.extend(cls_query)\n",
    "        \n",
    "        self.train_val_ids = support_ids\n",
    "        self.test_ids = query_ids\n",
    "        \n",
    "        print(f\"  支持集样本数: {len(support_ids)}\")\n",
    "        print(f\"  查询集样本数: {len(query_ids)}\")\n",
    "    \n",
    "    def _random_select(self, df):\n",
    "        \"\"\"随机选择样本\"\"\"\n",
    "        all_ids = df['Id'].tolist()\n",
    "        random.shuffle(all_ids)\n",
    "        \n",
    "        test_ratio = getattr(self.args_task, 'test_ratio', 0.2)\n",
    "        test_size = int(len(all_ids) * test_ratio)\n",
    "        \n",
    "        self.test_ids = all_ids[:test_size]\n",
    "        self.train_val_ids = all_ids[test_size:]\n",
    "\n",
    "\n",
    "class ImbalancedIDSelector(IDSelector):\n",
    "    \"\"\"不平衡数据ID选择器\"\"\"\n",
    "    \n",
    "    def _get_extra_params(self):\n",
    "        \"\"\"获取不平衡数据特定参数\"\"\"\n",
    "        return {\n",
    "            'imbalance_ratio': getattr(self.args_task, 'imbalance_ratio', 0.1),\n",
    "            'minority_labels': getattr(self.args_task, 'minority_labels', None),\n",
    "            'test_ratio': getattr(self.args_task, 'test_ratio', 0.2),\n",
    "            'stratify': getattr(self.args_task, 'stratify', True)\n",
    "        }\n",
    "    \n",
    "    def _select_ids(self):\n",
    "        \"\"\"不平衡数据ID选择\"\"\"\n",
    "        # 过滤数据集\n",
    "        filtered_df = self.metadata.df[\n",
    "            self.metadata.df['Dataset_id'].isin(self.args_task.target_dataset_id)]\n",
    "        \n",
    "        # 检查标签列\n",
    "        label_col = getattr(self.args_task, 'label_column', 'Label')\n",
    "        if label_col not in filtered_df.columns:\n",
    "            print(f\"警告: 找不到标签列 '{label_col}'，无法执行不平衡采样\")\n",
    "            # 回退到随机选择\n",
    "            self._random_select(filtered_df)\n",
    "            return\n",
    "        \n",
    "        # 获取所有可用类别及其样本数\n",
    "        class_counts = filtered_df[label_col].value_counts().to_dict()\n",
    "        \n",
    "        # 确定多数类和少数类\n",
    "        if hasattr(self.args_task, 'minority_labels') and self.args_task.minority_labels:\n",
    "            # 明确指定少数类\n",
    "            minority_labels = self.args_task.minority_labels\n",
    "            majority_labels = [l for l in class_counts.keys() if l not in minority_labels]\n",
    "        else:\n",
    "            # 按样本数量自动确定\n",
    "            median_count = np.median(list(class_counts.values()))\n",
    "            minority_labels = [l for l, c in class_counts.items() if c < median_count]\n",
    "            majority_labels = [l for l, c in class_counts.items() if c >= median_count]\n",
    "        \n",
    "        # 设置不平衡比例\n",
    "        imbalance_ratio = getattr(self.args_task, 'imbalance_ratio', 0.1)\n",
    "        \n",
    "        print(f\"不平衡数据采样 - 比例: {imbalance_ratio}\")\n",
    "        print(f\"  多数类: {majority_labels}\")\n",
    "        print(f\"  少数类: {minority_labels}\")\n",
    "        \n",
    "        # 收集每个类别的样本\n",
    "        label_ids = {label: filtered_df[filtered_df[label_col] == label]['Id'].tolist() \n",
    "                    for label in class_counts.keys()}\n",
    "        \n",
    "        # 设置随机种子\n",
    "        random.seed(getattr(self.args_task, 'seed', 42))\n",
    "        \n",
    "        # 计算不平衡采样\n",
    "        majority_samples = []\n",
    "        minority_samples = []\n",
    "        \n",
    "        # 对每个多数类采样\n",
    "        for label in majority_labels:\n",
    "            majority_samples.extend(label_ids[label])\n",
    "        \n",
    "        # 对每个少数类采样\n",
    "        target_minority_count = int(len(majority_samples) * imbalance_ratio)\n",
    "        minority_count_per_class = target_minority_count // len(minority_labels) if minority_labels else 0\n",
    "        \n",
    "        for label in minority_labels:\n",
    "            available = label_ids[label]\n",
    "            if len(available) <= minority_count_per_class:\n",
    "                # 如果样本不足，全部使用\n",
    "                minority_samples.extend(available)\n",
    "            else:\n",
    "                # 随机采样\n",
    "                sampled = random.sample(available, minority_count_per_class)\n",
    "                minority_samples.extend(sampled)\n",
    "        \n",
    "        # 合并所有样本\n",
    "        all_samples = majority_samples + minority_samples\n",
    "        \n",
    "        # 划分训练集和测试集\n",
    "        test_ratio = getattr(self.args_task, 'test_ratio', 0.2)\n",
    "        stratify = getattr(self.args_task, 'stratify', True)\n",
    "        \n",
    "        if stratify:\n",
    "            # 使用分层抽样\n",
    "            sample_labels = [filtered_df.loc[id, label_col] for id in all_samples]\n",
    "            train_ids, test_ids = train_test_split(\n",
    "                all_samples, test_size=test_ratio, \n",
    "                stratify=sample_labels,\n",
    "                random_state=getattr(self.args_task, 'seed', 42)\n",
    "            )\n",
    "        else:\n",
    "            # 随机抽样\n",
    "            random.shuffle(all_samples)\n",
    "            split_idx = int(len(all_samples) * (1 - test_ratio))\n",
    "            train_ids = all_samples[:split_idx]\n",
    "            test_ids = all_samples[split_idx:]\n",
    "        \n",
    "        self.train_val_ids = train_ids\n",
    "        self.test_ids = test_ids\n",
    "        \n",
    "        # 打印统计信息\n",
    "        print(f\"  训练集样本数: {len(train_ids)}\")\n",
    "        print(f\"  测试集样本数: {len(test_ids)}\")\n",
    "    \n",
    "    def _random_select(self, df):\n",
    "        \"\"\"随机选择样本\"\"\"\n",
    "        all_ids = df['Id'].tolist()\n",
    "        random.shuffle(all_ids)\n",
    "        \n",
    "        test_ratio = getattr(self.args_task, 'test_ratio', 0.2)\n",
    "        test_size = int(len(all_ids) * test_ratio)\n",
    "        \n",
    "        self.test_ids = all_ids[:test_size]\n",
    "        self.train_val_ids = all_ids[test_size:]\n",
    "\n",
    "\n",
    "# 在data_factory类中添加ID选择功能\n",
    "def search_id(self):\n",
    "    \"\"\"\n",
    "    根据任务配置选择合适的ID选择器，并执行ID选择\n",
    "    \n",
    "    返回:\n",
    "        tuple: (train_val_ids, test_ids) 训练/验证ID列表和测试ID列表\n",
    "    \"\"\"\n",
    "    # 根据任务参数选择合适的选择器\n",
    "    selector_type = getattr(self.args_task, 'selector', 'default')\n",
    "    \n",
    "    if selector_type == 'few_shot':\n",
    "        selector = FewShotIDSelector(self.metadata, self.args_task)\n",
    "    elif selector_type == 'imbalanced':\n",
    "        selector = ImbalancedIDSelector(self.metadata, self.args_task)\n",
    "    else:\n",
    "        # 默认使用DG选择器\n",
    "        selector = DGIDSelector(self.metadata, self.args_task)\n",
    "    \n",
    "    # 执行ID选择\n",
    "    self.train_val_ids, self.test_ids = selector.select()\n",
    "    \n",
    "    # 可以保存选择器以便后续可视化\n",
    "    self.id_selector = selector\n",
    "    \n",
    "    return self.train_val_ids, self.test_ids\n",
    "\n",
    "\n",
    "# 向data_factory类添加可视化方法\n",
    "def visualize_data_split(self, save_path=None):\n",
    "    \"\"\"\n",
    "    可视化数据划分结果\n",
    "    \n",
    "    参数:\n",
    "        save_path: 图表保存路径，如果为None则显示图表\n",
    "    \"\"\"\n",
    "    if hasattr(self, 'id_selector'):\n",
    "        self.id_selector.visualize(save_path)\n",
    "    else:\n",
    "        print(\"警告: 必须先调用search_id方法才能可视化数据划分\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
