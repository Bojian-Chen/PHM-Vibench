# ISFM_Prompt åµŒå…¥ç»„ä»¶æŠ€æœ¯æ–‡æ¡£

## ç›®å½•

1. [ç»„ä»¶æ¦‚è§ˆ](#1-ç»„ä»¶æ¦‚è§ˆ)
2. [E_01_HSE_v2 - ç ”ç©¶çº§HSEåµŒå…¥](#2-e_01_hse_v2---ç ”ç©¶çº§hseåµŒå…¥)
3. [HSE_prompt - è½»é‡åŒ–HSEåµŒå…¥](#3-hse_prompt---è½»é‡åŒ–hseåµŒå…¥)
4. [æŠ€æœ¯å¯¹æ¯”åˆ†æ](#4-æŠ€æœ¯å¯¹æ¯”åˆ†æ)
5. [é›†æˆä½¿ç”¨æŒ‡å—](#5-é›†æˆä½¿ç”¨æŒ‡å—)
6. [é«˜çº§åŠŸèƒ½](#6-é«˜çº§åŠŸèƒ½)
7. [æ•…éšœæ’é™¤](#7-æ•…éšœæ’é™¤)

---

## 1. ç»„ä»¶æ¦‚è§ˆ

ISFM_PromptåµŒå…¥ç»„ä»¶æä¾›ä¸¤ç§ä¸åŒçš„åˆ†å±‚ä¿¡å·åµŒå…¥ï¼ˆHSEï¼‰å®ç°ï¼Œåˆ†åˆ«é’ˆå¯¹ä¸åŒçš„åº”ç”¨åœºæ™¯å’Œå¤æ‚åº¦éœ€æ±‚è®¾è®¡ã€‚

### 1.1 HSEåµŒå…¥æ¶æ„ä»‹ç»

**åˆ†å±‚ä¿¡å·åµŒå…¥ï¼ˆHierarchical Signal Embedding, HSEï¼‰** æ˜¯é’ˆå¯¹å·¥ä¸šæŒ¯åŠ¨ä¿¡å·è®¾è®¡çš„ä¸“é—¨åµŒå…¥æ–¹æ³•ï¼Œæ ¸å¿ƒç‰¹ç‚¹ï¼š

- **è¡¥ä¸åŒ–å¤„ç†**ï¼šå°†é•¿æ—¶é—´åºåˆ—åˆ†å‰²ä¸ºå›ºå®šé•¿åº¦çš„è¡¥ä¸
- **æ—¶é—´ç¼–ç **ï¼šä¸ºæ¯ä¸ªè¡¥ä¸æ·»åŠ ä½ç½®å’Œæ—¶é—´ä¿¡æ¯
- **Promptå¼•å¯¼**ï¼šåˆ©ç”¨æ•°æ®é›†ç‰¹å®šä¿¡æ¯å¢å¼ºåµŒå…¥è¡¨ç¤º
- **è·¨åŸŸæ³›åŒ–**ï¼šæ”¯æŒä¸åŒå·¥ä¸šè®¾å¤‡å’Œè¿è¡Œæ¡ä»¶çš„æ³›åŒ–

### 1.2 ä¸¤ç§å®ç°å¯¹æ¯”

| ç‰¹æ€§ | E_01_HSE_v2 | HSE_prompt |
|------|------------|------------|
| **è®¾è®¡ç›®æ ‡** | ç ”ç©¶çº§é«˜çº§å®ç° | è½»é‡åŒ–åŸºç¡€å®ç° |
| **Promptå¤æ‚åº¦** | åŒå±‚ç¼–ç ï¼ˆç³»ç»Ÿ+æ ·æœ¬ï¼‰ | å•å±‚ç¼–ç ï¼ˆæ•°æ®é›†ï¼‰ |
| **èåˆç­–ç•¥** | 3ç§ï¼ˆæ‹¼æ¥ã€æ³¨æ„åŠ›ã€é—¨æ§ï¼‰ | 2ç§ï¼ˆåŠ æ³•ã€æ‹¼æ¥ï¼‰ |
| **å†…å­˜ä½¿ç”¨** | è¾ƒé«˜ï¼ˆO(nÂ²)æ³¨æ„åŠ›ï¼‰ | è¾ƒä½ï¼ˆO(1)æŸ¥æ‰¾ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | è·¨åŸŸç ”ç©¶ã€å¤æ‚å®éªŒ | æ•™è‚²æ¼”ç¤ºã€åŸºçº¿å¯¹æ¯” |
| **å­¦ä¹ æ›²çº¿** | é™¡å³­ | å¹³ç¼“ |
| **åŠŸèƒ½å®Œæ•´æ€§** | é«˜çº§åŠŸèƒ½å®Œæ•´ | åŸºç¡€åŠŸèƒ½å®Œå¤‡ |

### 1.3 é€‰æ‹©æŒ‡å—

#### é€‰æ‹© **E_01_HSE_v2** çš„æƒ…å†µï¼š
- ğŸ”¬ **ç ”ç©¶é¡¹ç›®**ï¼šéœ€è¦æ¢ç´¢å¤æ‚çš„Promptèåˆç­–ç•¥
- ğŸŒ **è·¨åŸŸæ³›åŒ–**ï¼šå¤„ç†å¤šä¸ªæ•°æ®åŸŸçš„å¤æ‚å…³ç³»
- ğŸ¯ **æ€§èƒ½ä¼˜å…ˆ**ï¼šè¿½æ±‚æœ€ä½³çš„æ¨¡å‹æ€§èƒ½
- ğŸ“Š **è®ºæ–‡å®éªŒ**ï¼šéœ€è¦ä¸°å¯Œçš„ç ”ç©¶å¯¹æ¯”æ•°æ®
- ğŸ’¾ **èµ„æºå……è¶³**ï¼šæœ‰è¶³å¤Ÿçš„è®¡ç®—å’Œå†…å­˜èµ„æº

#### é€‰æ‹© **HSE_prompt** çš„æƒ…å†µï¼š
- ğŸ“ **æ•™è‚²æ¼”ç¤º**ï¼šæ•™å­¦å’Œæ¦‚å¿µéªŒè¯
- âš¡ **å¿«é€ŸåŸå‹**ï¼šå¿«é€Ÿå®ç°æƒ³æ³•å’ŒéªŒè¯
- ğŸ“š **åŸºçº¿å¯¹æ¯”**ï¼šä½œä¸ºå®éªŒå¯¹æ¯”çš„åŸºçº¿
- ğŸ”§ **èµ„æºå—é™**ï¼šè®¡ç®—å’Œå†…å­˜èµ„æºæœ‰é™
- ğŸš€ **ç®€å•éƒ¨ç½²**ï¼šéœ€è¦å¿«é€Ÿéƒ¨ç½²å’Œé›†æˆ

**ä¸ Vbench å®éªŒçš„å…³ç³»ï¼š**

- Experiment 2ï¼ˆHSE å¯¹æ¯”é¢„è®­ç»ƒ + ä¸‹æ¸¸ CDDGï¼‰  
  ä½¿ç”¨çš„æ˜¯ `src/model_factory/ISFM/embedding/E_01_HSE.py`ï¼ˆæ—  prompt åŸºçº¿ï¼‰ï¼Œå¹¶ä¸ç›´æ¥ä¾èµ–æœ¬ç›®å½•ç»„ä»¶ã€‚

- Experiment 3ï¼ˆHSE-Prompt + CDDGï¼Œä¸‹æ¸¸é˜¶æ®µï¼‰  
  æ¨èä½¿ç”¨ **`HSE_prompt`** ä½œä¸º Experiment 3â€“7 çš„é»˜è®¤ Prompt åµŒå…¥å®ç°ï¼š  
  - è½»é‡åŒ–ã€æ˜“äºè°ƒè¯•ï¼›  
  - å·²æ”¯æŒ per-sample `fs` ä¸ `dataset_ids`ï¼Œåœ¨å¼‚æ„ batch ä¸‹ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œã€‚

- `E_01_HSE_v2`  
  ä½œä¸ºâ€œç ”ç©¶çº§ Prompt HSEâ€ä¿ç•™ï¼Œç”¨äºæ›´å¤æ‚çš„ Prompt èåˆç­–ç•¥æ¢ç´¢ï¼ˆå¦‚ Pipeline_03 æˆ–è®ºæ–‡æ‰©å±•å®éªŒï¼‰ï¼Œå½“å‰å®éªŒ 0â€“7 çš„ç»Ÿä¸€é…ç½®ä¸é»˜è®¤ä½¿ç”¨å®ƒã€‚ 
---

## 2. E_01_HSE_v2 - ç ”ç©¶çº§HSEåµŒå…¥

### 2.1 æ¶æ„è®¾è®¡

E_01_HSE_v2å®ç°äº†ä¸€ä¸ªå¤æ‚çš„åŒå±‚Promptç³»ç»Ÿï¼Œä¸ºé«˜çº§ç ”ç©¶åº”ç”¨æä¾›å¼ºå¤§çš„è¡¨å¾å­¦ä¹ èƒ½åŠ›ã€‚

```python
class E_01_HSE_v2(nn.Module):
    """ç ”ç©¶çº§åˆ†å±‚ä¿¡å·åµŒå…¥v2

    ç‰¹ç‚¹ï¼š
    - åŒå±‚Promptç¼–ç ï¼šç³»ç»Ÿçº§ + æ ·æœ¬çº§
    - é«˜çº§èåˆç­–ç•¥ï¼šæ³¨æ„åŠ›æœºåˆ¶ + é—¨æ§
    - é˜¶æ®µæ„ŸçŸ¥è®­ç»ƒï¼šæ”¯æŒpretraining/finetuneé˜¶æ®µ
    - å†…å­˜ä¼˜åŒ–ï¼šå¤§è§„æ¨¡æ•°æ®å¤„ç†ä¼˜åŒ–
    """
```

#### æ ¸å¿ƒæ¶æ„ç»„ä»¶

1. **ç³»ç»Ÿçº§Promptç¼–ç å™¨**
   - å¤„ç†æ•°æ®é›†IDï¼ˆDataset_idï¼‰
   - å¤„ç†åŸŸIDï¼ˆDomain_idï¼‰
   - æ”¯æŒå¤šç³»ç»Ÿèåˆ

2. **æ ·æœ¬çº§Promptç¼–ç å™¨**
   - å¤„ç†é‡‡æ ·ç‡ä¿¡æ¯ï¼ˆSample_rateï¼‰
   - æ—¶é—´æˆ³ç¼–ç 
   - ä¿¡å·ç‰¹å¾è‡ªé€‚åº”

3. **Promptèåˆæ¨¡å—**
   - æ³¨æ„åŠ›èåˆæœºåˆ¶
   - é—¨æ§èåˆç­–ç•¥
   - æ‹¼æ¥èåˆæ–¹æ¡ˆ

### 2.2 åŒå±‚Promptç³»ç»Ÿ

#### ç¬¬ä¸€å±‚ï¼šç³»ç»Ÿçº§ç¼–ç 
```python
def encode_system_prompts(self, dataset_ids, domain_ids=None):
    """
    ç¼–ç ç³»ç»Ÿçº§Promptä¿¡æ¯

    Args:
        dataset_ids: æ•°æ®é›†IDå¼ é‡ [batch_size]
        domain_ids: åŸŸIDå¼ é‡ [batch_size] (å¯é€‰)

    Returns:
        system_prompts: ç³»ç»Ÿçº§ç‰¹å¾ [batch_size, system_prompt_dim]
    """
    # æ•°æ®é›†åµŒå…¥
    dataset_embeddings = self.dataset_prompt_encoder(dataset_ids)

    # åŸŸåµŒå…¥ï¼ˆå¦‚æœæä¾›ï¼‰
    if domain_ids is not None:
        domain_embeddings = self.domain_prompt_encoder(domain_ids)
        # èåˆæ•°æ®é›†å’ŒåŸŸä¿¡æ¯
        system_prompts = self.fuse_system_prompts(dataset_embeddings, domain_embeddings)
    else:
        system_prompts = dataset_embeddings

    return system_prompts
```

#### ç¬¬äºŒå±‚ï¼šæ ·æœ¬çº§ç¼–ç 
```python
def encode_sample_prompts(self, sample_rates, timestamps=None):
    """
    ç¼–ç æ ·æœ¬çº§Promptä¿¡æ¯

    Args:
        sample_rates: é‡‡æ ·ç‡å¼ é‡ [batch_size]
        timestamps: æ—¶é—´æˆ³å¼ é‡ [batch_size] (å¯é€‰)

    Returns:
        sample_prompts: æ ·æœ¬çº§ç‰¹å¾ [batch_size, sample_prompt_dim]
    """
    # é‡‡æ ·ç‡ç¼–ç 
    rate_embeddings = self.sample_rate_encoder(sample_rates)

    # æ—¶é—´æˆ³ç¼–ç ï¼ˆå¦‚æœæä¾›ï¼‰
    if timestamps is not None:
        time_embeddings = self.timestamp_encoder(timestamps)
        sample_prompts = torch.cat([rate_embeddings, time_embeddings], dim=-1)
    else:
        sample_prompts = rate_embeddings

    return sample_prompts
```

### 2.3 é«˜çº§èåˆç­–ç•¥

#### æ³¨æ„åŠ›èåˆ
```python
class AttentionFusion(nn.Module):
    """æ³¨æ„åŠ›èåˆæœºåˆ¶"""

    def __init__(self, feature_dim, num_heads=8):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=feature_dim,
            num_heads=num_heads,
            batch_first=True
        )

    def forward(self, hse_features, system_prompts, sample_prompts):
        """å¤šå¤´æ³¨æ„åŠ›èåˆ"""
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        all_features = torch.stack([hse_features, system_prompts, sample_prompts], dim=1)

        # æ³¨æ„åŠ›è®¡ç®—
        attended_features, attention_weights = self.attention(
            all_features, all_features, all_features
        )

        return attended_features[:, 0]  # è¿”å›å¢å¼ºçš„HSEç‰¹å¾
```

#### é—¨æ§èåˆ
```python
class GatingFusion(nn.Module):
    """é—¨æ§èåˆæœºåˆ¶"""

    def __init__(self, feature_dim):
        super().__init__()
        self.gate_net = nn.Sequential(
            nn.Linear(feature_dim * 3, feature_dim),
            nn.ReLU(),
            nn.Linear(feature_dim, feature_dim),
            nn.Sigmoid()
        )

    def forward(self, hse_features, system_prompts, sample_prompts):
        """é—¨æ§ç‰¹å¾èåˆ"""
        # æ‹¼æ¥ç‰¹å¾
        combined_features = torch.cat([hse_features, system_prompts, sample_prompts], dim=-1)

        # è®¡ç®—é—¨æ§æƒé‡
        gates = self.gate_net(combined_features)

        # åŠ æƒèåˆ
        fused_features = gates * hse_features + (1 - gates) * (
            system_prompts + sample_prompts
        ) / 2

        return fused_features
```

### 2.4 APIå‚è€ƒ

#### åˆå§‹åŒ–å‚æ•°
```python
def __init__(self, args_model, metadata):
    """
    åˆå§‹åŒ–E_01_HSE_v2

    Args:
        args_model: æ¨¡å‹é…ç½®å‚æ•°
        metadata: å…ƒæ•°æ®å­—å…¸

    å…³é”®å‚æ•°ï¼š
        - patch_size_L: è¡¥ä¸é•¿åº¦ (é»˜è®¤: 16)
        - num_patches: è¡¥ä¸æ•°é‡ (é»˜è®¤: 64)
        - output_dim: è¾“å‡ºç»´åº¦ (é»˜è®¤: 128)
        - prompt_dim: Promptç»´åº¦ (é»˜è®¤: 64)
        - fusion_type: èåˆç±»å‹ ("concat"/"attention"/"gating")
        - max_dataset_ids: æœ€å¤§æ•°æ®é›†IDæ•° (é»˜è®¤: 50)
        - max_domain_ids: æœ€å¤§åŸŸIDæ•° (é»˜è®¤: 50)
        - training_stage: è®­ç»ƒé˜¶æ®µ ("pretraining"/"finetune")
    """
```

#### å‰å‘ä¼ æ’­
```python
def forward(self, x, dataset_ids=None, sample_rates=None, **kwargs):
    """
    å‰å‘ä¼ æ’­

    Args:
        x: è¾“å…¥ä¿¡å· [batch_size, channels, length]
        dataset_ids: æ•°æ®é›†ID [batch_size]
        sample_rates: é‡‡æ ·ç‡ [batch_size]
        **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚domain_ids, timestampsï¼‰

    Returns:
        output: åµŒå…¥ç‰¹å¾ [batch_size, num_patches, output_dim]
    """
```

### 2.5 é…ç½®å‚æ•°

```yaml
model:
  embedding: "E_01_HSE_v2"

  # HSEåŸºç¡€å‚æ•°
  patch_size_L: 16              # è¡¥ä¸é•¿åº¦
  num_patches: 64               # è¡¥ä¸æ•°é‡
  output_dim: 128               # è¾“å‡ºç»´åº¦

  # Promptå‚æ•°
  prompt_dim: 64                # Promptç‰¹å¾ç»´åº¦
  fusion_type: "attention"      # èåˆç­–ç•¥: concat/attention/gating
  max_dataset_ids: 50           # æ”¯æŒçš„æœ€å¤§æ•°æ®é›†æ•°
  max_domain_ids: 50            # æ”¯æŒçš„æœ€å¤§åŸŸæ•°

  # è®­ç»ƒå‚æ•°
  training_stage: "pretraining"  # è®­ç»ƒé˜¶æ®µ
  freeze_prompts: false         # æ˜¯å¦å†»ç»“Prompt

  # ä¼˜åŒ–å‚æ•°
  prompt_lr_multiplier: 0.1     # Promptå­¦ä¹ ç‡å€æ•°
  dropout_rate: 0.1             # Dropoutç‡
```

---

## 3. HSE_prompt - è½»é‡åŒ–HSEåµŒå…¥

### 3.1 è®¾è®¡ç†å¿µ

HSE_promptä¸“æ³¨äºæä¾›ä¸€ä¸ªç®€æ´ã€é«˜æ•ˆçš„HSEå®ç°ï¼Œé€‚åˆæ•™è‚²æ¼”ç¤ºã€å¿«é€ŸåŸå‹å’ŒåŸºçº¿å¯¹æ¯”ã€‚

```python
class HSE_prompt(nn.Module):
    """è½»é‡åŒ–åˆ†å±‚ä¿¡å·åµŒå…¥

    ç‰¹ç‚¹ï¼š
    - å•å±‚Promptç¼–ç ï¼šä»…æ•°æ®é›†çº§
    - ç®€åŒ–èåˆç­–ç•¥ï¼šåŠ æ³•å’Œæ‹¼æ¥
    - è½»é‡çº§å®ç°ï¼šä½å†…å­˜å ç”¨
    - æ˜“äºç†è§£ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„
    """
```

### 3.2 ç®€åŒ–Promptæœºåˆ¶

#### å•å±‚Promptç¼–ç 
```python
def encode_dataset_prompts(self, dataset_ids):
    """
    ç¼–ç æ•°æ®é›†Promptä¿¡æ¯

    Args:
        dataset_ids: æ•°æ®é›†IDå¼ é‡ [batch_size]

    Returns:
        dataset_prompts: æ•°æ®é›†ç‰¹å¾ [batch_size, prompt_dim]
    """
    # ç®€å•çš„åµŒå…¥æŸ¥æ‰¾
    return self.dataset_prompt_encoder(dataset_ids)
```

#### åŸºç¡€èåˆç­–ç•¥
```python
def fuse_features(self, hse_features, dataset_prompts, fusion_type="add"):
    """
    ç‰¹å¾èåˆ

    Args:
        hse_features: HSEç‰¹å¾ [batch_size, num_patches, output_dim]
        dataset_prompts: æ•°æ®é›†Prompt [batch_size, prompt_dim]
        fusion_type: èåˆç±»å‹ ("add"/"concat")

    Returns:
        fused_features: èåˆåç‰¹å¾
    """
    if fusion_type == "add":
        # åŠ æ³•èåˆï¼ˆéœ€è¦ç»´åº¦åŒ¹é…ï¼‰
        if hse_features.size(-1) != dataset_prompts.size(-1):
            dataset_prompts = self.prompt_projection(dataset_prompts)
        return hse_features + dataset_prompts.unsqueeze(1)

    elif fusion_type == "concat":
        # æ‹¼æ¥èåˆ
        dataset_prompts = dataset_prompts.unsqueeze(1).expand(-1, hse_features.size(1), -1)
        return torch.cat([hse_features, dataset_prompts], dim=-1)
```

### 3.3 åŸºç¡€èåˆç­–ç•¥

#### åŠ æ³•èåˆ
```python
class AdditiveFusion(nn.Module):
    """åŠ æ³•èåˆ"""

    def __init__(self, feature_dim, prompt_dim):
        super().__init__()
        # ç»´åº¦åŒ¹é…æŠ•å½±
        if feature_dim != prompt_dim:
            self.prompt_projection = nn.Linear(prompt_dim, feature_dim)
        else:
            self.prompt_projection = nn.Identity()

    def forward(self, features, prompts):
        """ç®€å•çš„åŠ æ³•èåˆ"""
        projected_prompts = self.prompt_projection(prompts)
        return features + projected_prompts.unsqueeze(1)
```

#### æ‹¼æ¥èåˆ
```python
class ConcatFusion(nn.Module):
    """æ‹¼æ¥èåˆ"""

    def __init__(self, feature_dim, prompt_dim):
        super().__init__()
        # æ‹¼æ¥åçš„ç»´åº¦å˜æ¢
        self.output_projection = nn.Linear(feature_dim + prompt_dim, feature_dim)

    def forward(self, features, prompts):
        """ç‰¹å¾æ‹¼æ¥èåˆ"""
        batch_size, num_patches, _ = features.shape
        prompts_expanded = prompts.unsqueeze(1).expand(-1, num_patches, -1)

        concatenated = torch.cat([features, prompts_expanded], dim=-1)
        return self.output_projection(concatenated)
```

### 3.4 APIå‚è€ƒ

#### åˆå§‹åŒ–å‚æ•°
```python
def __init__(self, args_model, metadata):
    """
    åˆå§‹åŒ–HSE_prompt

    Args:
        args_model: æ¨¡å‹é…ç½®å‚æ•°
        metadata: å…ƒæ•°æ®å­—å…¸

    å…³é”®å‚æ•°ï¼š
        - patch_size_L: è¡¥ä¸é•¿åº¦ (é»˜è®¤: 16)
        - num_patches: è¡¥ä¸æ•°é‡ (é»˜è®¤: 64)
        - output_dim: è¾“å‡ºç»´åº¦ (é»˜è®¤: 128)
        - use_prompt: æ˜¯å¦ä½¿ç”¨Prompt (é»˜è®¤: true)
        - prompt_dim: Promptç»´åº¦ (é»˜è®¤: 64)
        - max_dataset_ids: æœ€å¤§æ•°æ®é›†IDæ•° (é»˜è®¤: 30)
        - prompt_combination: Promptç»„åˆæ–¹å¼ ("add"/"concat")
    """
```

#### å‰å‘ä¼ æ’­
```python
def forward(self, x, dataset_ids=None, **kwargs):
    """
    å‰å‘ä¼ æ’­

    Args:
        x: è¾“å…¥ä¿¡å· [batch_size, channels, length]
        dataset_ids: æ•°æ®é›†ID [batch_size]
        **kwargs: å…¶ä»–å‚æ•°ï¼ˆé€šå¸¸ä¸ºç©ºï¼‰

    Returns:
        output: åµŒå…¥ç‰¹å¾ [batch_size, num_patches, output_dim]
    """
```

### 3.5 é…ç½®å‚æ•°

```yaml
model:
  embedding: "HSE_prompt"

  # HSEåŸºç¡€å‚æ•°
  patch_size_L: 16              # è¡¥ä¸é•¿åº¦
  num_patches: 64               # è¡¥ä¸æ•°é‡
  output_dim: 128               # è¾“å‡ºç»´åº¦

  # Promptå‚æ•°
  use_prompt: true              # æ˜¯å¦ä½¿ç”¨Prompt
  prompt_dim: 64                # Promptç‰¹å¾ç»´åº¦
  max_dataset_ids: 30           # æ”¯æŒçš„æœ€å¤§æ•°æ®é›†æ•°
  prompt_combination: "add"      # Promptç»„åˆæ–¹å¼: add/concat

  # ç®€åŒ–å‚æ•°
  dropout_rate: 0.1             # Dropoutç‡
  normalize_features: true      # ç‰¹å¾æ ‡å‡†åŒ–
```

---

## 4. æŠ€æœ¯å¯¹æ¯”åˆ†æ

### 4.1 åŠŸèƒ½å¯¹æ¯”è¡¨

| åŠŸèƒ½ç‰¹æ€§ | E_01_HSE_v2 | HSE_prompt |
|----------|------------|------------|
| **Promptå¤æ‚åº¦** | åŒå±‚ï¼ˆç³»ç»Ÿ+æ ·æœ¬ï¼‰ | å•å±‚ï¼ˆæ•°æ®é›†ï¼‰ |
| **èåˆç­–ç•¥** | æ³¨æ„åŠ›ã€é—¨æ§ã€æ‹¼æ¥ | åŠ æ³•ã€æ‹¼æ¥ |
| **åŸŸæ”¯æŒ** | âœ… æ”¯æŒå¤šåŸŸ | âŒ ä¸æ”¯æŒåŸŸä¿¡æ¯ |
| **æ—¶é—´ç¼–ç ** | âœ… å®Œæ•´æ—¶é—´æˆ³ç¼–ç  | âŒ ä»…æ”¯æŒé‡‡æ ·ç‡ |
| **é˜¶æ®µæ„ŸçŸ¥** | âœ… æ”¯æŒè®­ç»ƒé˜¶æ®µæ§åˆ¶ | âŒ åŸºç¡€è®­ç»ƒæ§åˆ¶ |
| **å†…å­˜ä¼˜åŒ–** | âœ… å¤§è§„æ¨¡ä¼˜åŒ– | âŒ åŸºç¡€å†…å­˜ç®¡ç† |
| **è®¡ç®—å¤æ‚åº¦** | O(nÂ²)æ³¨æ„åŠ› | O(1)æŸ¥æ‰¾ |
| **å‚æ•°æ•°é‡** | çº¦2.5Må‚æ•° | çº¦1.2Må‚æ•° |
| **è®­ç»ƒç¨³å®šæ€§** | é«˜ï¼ˆéœ€è¦è°ƒå‚ï¼‰ | é«˜ï¼ˆç¨³å®šæ”¶æ•›ï¼‰ |
| **æ‰©å±•æ€§** | é«˜åº¦å¯æ‰©å±• | åŸºç¡€æ‰©å±•èƒ½åŠ› |

### 4.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

#### å†…å­˜ä½¿ç”¨å¯¹æ¯”
```python
# åŸºå‡†æµ‹è¯•ç»“æœï¼ˆbatch_size=32, sequence_length=1024ï¼‰
memory_usage = {
    "E_01_HSE_v2": {
        "GPU_memory": "1.2GB",
        "CPU_memory": "800MB",
        "peak_memory": "1.5GB"
    },
    "HSE_prompt": {
        "GPU_memory": "600MB",
        "CPU_memory": "400MB",
        "peak_memory": "750MB"
    }
}
```

#### è®­ç»ƒé€Ÿåº¦å¯¹æ¯”
```python
# æ¯epochè®­ç»ƒæ—¶é—´ï¼ˆç›¸åŒç¡¬ä»¶é…ç½®ï¼‰
training_time = {
    "E_01_HSE_v2": "45s/epoch",
    "HSE_prompt": "28s/epoch"
}

# æ¨ç†å»¶è¿Ÿï¼ˆå•æ ·æœ¬ï¼Œmsï¼‰
inference_latency = {
    "E_01_HSE_v2": 12.5,
    "HSE_prompt": 8.3
}
```

### 4.3 é€‚ç”¨åœºæ™¯åˆ†æ

#### E_01_HSE_v2 æœ€ä½³åœºæ™¯

1. **è·¨åŸŸæ•…éšœè¯Šæ–­**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šå¤šåŸŸæ•…éšœè¯Šæ–­
   model:
     embedding: "E_01_HSE_v2"
     fusion_type: "attention"
     max_domain_ids: 20
     training_stage: "pretraining"

   data:
     domains: ["bearing", "gear", "motor", "pump"]
     cross_domain: true
   ```

2. **å¤šä¼ æ„Ÿå™¨èåˆ**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šå¤šä¼ æ„Ÿå™¨æ•°æ®
   model:
     embedding: "E_01_HSE_v2"
     fusion_type: "gating"
     prompt_dim: 128

   sensors: ["vibration", "acoustic", "thermal", "current"]
   ```

3. **é«˜çº§ç ”ç©¶å®éªŒ**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šè®ºæ–‡å®éªŒ
   model:
     embedding: "E_01_HSE_v2"
     fusion_type: "attention"
     training_stage: "finetune"
     freeze_prompts: false

   experiment:
     type: "cross_dataset_generalization"
     baseline: true
   ```

#### HSE_prompt æœ€ä½³åœºæ™¯

1. **æ•™å­¦æ¼”ç¤º**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šæ•™å­¦æ¼”ç¤º
   model:
     embedding: "HSE_prompt"
     use_prompt: true
     prompt_combination: "add"

   educational:
     visualize_features: true
     explain_prompt_effect: true
   ```

2. **å¿«é€ŸåŸå‹éªŒè¯**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šå¿«é€ŸéªŒè¯
   model:
     embedding: "HSE_prompt"
     output_dim: 64
     num_patches: 32

   experiment:
     type: "quick_validation"
     max_epochs: 10
   ```

3. **åŸºçº¿å¯¹æ¯”**
   ```yaml
   # é…ç½®ç¤ºä¾‹ï¼šåŸºçº¿å®éªŒ
   model:
     embedding: "HSE_prompt"
     use_prompt: false  # æ— PromptåŸºçº¿

   comparison:
     baselines: ["HSE_prompt", "RawFeatures", "FFT"]
     metrics: ["accuracy", "f1_score", "convergence"]
   ```

### 4.4 è¿ç§»æŒ‡å—

#### ä» HSE_prompt è¿ç§»åˆ° E_01_HSE_v2

```yaml
# åŸå§‹ HSE_prompt é…ç½®
model:
  embedding: "HSE_prompt"
  patch_size_L: 16
  output_dim: 128
  prompt_dim: 64
  prompt_combination: "add"

# è¿ç§»åˆ° E_01_HSE_v2 é…ç½®
model:
  embedding: "E_01_HSE_v2"
  patch_size_L: 16                    # ä¿æŒä¸å˜
  output_dim: 128                    # ä¿æŒä¸å˜
  prompt_dim: 64                      # ä¿æŒä¸å˜
  fusion_type: "attention"            # æ–°å¢ï¼šä½¿ç”¨æ›´é«˜çº§çš„èåˆ
  max_dataset_ids: 30                 # æ–°å¢ï¼šæ˜ç¡®æŒ‡å®šæ•°æ®é›†æ•°é‡
  max_domain_ids: 10                  # æ–°å¢ï¼šæ”¯æŒåŸŸä¿¡æ¯
  training_stage: "pretraining"       # æ–°å¢ï¼šè®­ç»ƒé˜¶æ®µæ§åˆ¶
```

#### ä»£ç è¿ç§»ç¤ºä¾‹

```python
# åŸå§‹ HSE_prompt ä½¿ç”¨æ–¹å¼
def train_with_hse_prompt():
    model = HSE_prompt(args_model, metadata)
    output = model(x, dataset_ids=dataset_ids)

# è¿ç§»åˆ° E_01_HSE_v2
def train_with_hse_v2():
    model = E_01_HSE_v2(args_model, metadata)

    # æ·»åŠ åŸŸä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    domain_ids = get_domain_ids(dataset_ids)
    sample_rates = get_sample_rates(dataset_ids)

    output = model(
        x,
        dataset_ids=dataset_ids,
        domain_ids=domain_ids,
        sample_rates=sample_rates
    )
```

---

## 5. é›†æˆä½¿ç”¨æŒ‡å—

### 5.1 ISFM_Promptæ¨¡å‹é›†æˆ

#### å®Œæ•´æ¨¡å‹é…ç½®
```yaml
# å®Œæ•´çš„ISFM_Prompté…ç½®ç¤ºä¾‹
experiment_name: "HSE_Prompt_Fault_Diagnosis"

# æ¨¡å‹é…ç½®
model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"

  # åµŒå…¥å±‚é€‰æ‹©
  embedding: "E_01_HSE_v2"          # æˆ– "HSE_prompt"

  # ä¸»å¹²ç½‘ç»œ
  backbone: "B_08_PatchTST"
  backbone_config:
    num_layers: 6
    num_heads: 8
    d_model: 512

  # ä»»åŠ¡å¤´
  task_head: "H_01_Linear_cla"
  num_classes: 10

# åµŒå…¥å±‚ç‰¹å®šé…ç½®
embedding_config:
  # E_01_HSE_v2 å‚æ•°
  patch_size_L: 16
  num_patches: 64
  output_dim: 128
  prompt_dim: 64
  fusion_type: "attention"
  max_dataset_ids: 50
  training_stage: "pretraining"

# æ•°æ®é…ç½®
data:
  train_datasets: ["CWRU", "XJTU", "THU"]
  test_datasets: ["Ottawa", "JNU"]

  # å…ƒæ•°æ®æ–‡ä»¶
  metadata_file: "data/metadata/combined_metadata.xlsx"

  # æ•°æ®é¢„å¤„ç†
  sample_rate: 12000
  window_length: 1024
  normalize: true

# è®­ç»ƒé…ç½®
training:
  epochs: 100
  batch_size: 32
  learning_rate: 1e-4

  # Promptç‰¹å®šä¼˜åŒ–
  prompt_lr_multiplier: 0.1
  freeze_prompt_epochs: 10
```

#### æ¨¡å‹å®ä¾‹åŒ–ä»£ç 
```python
from src.model_factory import model_factory
from src.configs.utils import create_namespace

def create_hse_prompt_model(config_path):
    """åˆ›å»ºHSE Promptæ¨¡å‹"""

    # åŠ è½½é…ç½®
    config = load_config(config_path)
    args_model = create_namespace(config.model)
    metadata = load_metadata(config.data.metadata_file)

    # åˆ›å»ºæ¨¡å‹
    model = model_factory(args_model, metadata)

    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model.__class__.__name__}")
    print(f"ğŸ“Š å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ğŸ”§ åµŒå…¥å±‚: {args_model.embedding}")

    return model

# ä½¿ç”¨ç¤ºä¾‹
model = create_hse_prompt_model("configs/hse_prompt_experiment.yaml")
```

### 5.2 é…ç½®æ–‡ä»¶æ¨¡æ¿

#### åŸºç¡€ç ”ç©¶é…ç½®
```yaml
# configs/research/hse_v2_research.yaml
model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"
  embedding: "E_01_HSE_v2"

  # é«˜çº§é…ç½®
  embedding_config:
    fusion_type: "attention"
    prompt_dim: 128
    max_dataset_ids: 100
    max_domain_ids: 20
    training_stage: "pretraining"
    freeze_prompts: false

# ç ”ç©¶ç‰¹å®šå‚æ•°
research:
  experiment_type: "cross_domain_generalization"
  baseline_comparison: true
  ablation_study: true

  # Ablationç ”ç©¶
  ablation_factors:
    - "fusion_type"
    - "prompt_dim"
    - "training_stage"
```

#### æ•™å­¦æ¼”ç¤ºé…ç½®
```yaml
# configs/education/hse_prompt_demo.yaml
model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"
  embedding: "HSE_prompt"

  # ç®€åŒ–é…ç½®
  embedding_config:
    use_prompt: true
    prompt_dim: 32
    prompt_combination: "add"
    max_dataset_ids: 10

# æ¼”ç¤ºç‰¹å®šå‚æ•°
education:
  visualize_features: true
  show_prompt_effects: true
  simplified_output: true
  step_by_step: true
```

### 5.3 ä»£ç ç¤ºä¾‹

#### åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
```python
import torch
from src.model_factory.ISFM_Prompt.embedding import E_01_HSE_v2, HSE_prompt

def basic_usage_example():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""

    # æ¨¡æ‹Ÿé…ç½®
    class Args:
        def __init__(self):
            # åŸºç¡€å‚æ•°
            self.patch_size_L = 16
            self.num_patches = 64
            self.output_dim = 128
            self.prompt_dim = 64

    # æ¨¡æ‹Ÿå…ƒæ•°æ®
    metadata = {
        'class_mapping': {0: 'normal', 1: 'fault1', 2: 'fault2'}
    }

    args_model = Args()

    # åˆ›å»ºE_01_HSE_v2
    print("ğŸ”¬ åˆ›å»ºE_01_HSE_v2...")
    hse_v2 = E_01_HSE_v2(args_model, metadata)

    # åˆ›å»ºHSE_prompt
    print("âš¡ åˆ›å»ºHSE_prompt...")
    hse_prompt = HSE_prompt(args_model, metadata)

    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 8
    x = torch.randn(batch_size, 2, 1024)          # [B, C, L]
    dataset_ids = torch.randint(0, 10, (batch_size,))  # [B]

    # å‰å‘ä¼ æ’­
    print("\nğŸ“Š å‰å‘ä¼ æ’­æµ‹è¯•...")

    # E_01_HSE_v2è¾“å‡º
    with torch.no_grad():
        output_v2 = hse_v2(x, dataset_ids=dataset_ids)
        print(f"E_01_HSE_v2 è¾“å‡ºå½¢çŠ¶: {output_v2.shape}")

    # HSE_promptè¾“å‡º
    with torch.no_grad():
        output_prompt = hse_prompt(x, dataset_ids=dataset_ids)
        print(f"HSE_prompt è¾“å‡ºå½¢çŠ¶: {output_prompt.shape}")

    print("âœ… åŸºç¡€ä½¿ç”¨æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    basic_usage_example()
```

#### é«˜çº§ä½¿ç”¨ç¤ºä¾‹
```python
def advanced_usage_example():
    """é«˜çº§ä½¿ç”¨ç¤ºä¾‹"""

    # åŠ è½½çœŸå®é…ç½®
    config = load_config("configs/advanced/hse_v2_config.yaml")
    args_model = create_namespace(config.model)
    metadata = load_metadata("data/metadata/industrial_datasets.xlsx")

    # åˆ›å»ºæ¨¡å‹
    model = E_01_HSE_v2(args_model, metadata)

    # æ¨¡æ‹Ÿå¤æ‚æ•°æ®
    batch_size = 16
    x = torch.randn(batch_size, 3, 4096)
    dataset_ids = torch.randint(0, 20, (batch_size,))
    domain_ids = torch.randint(0, 5, (batch_size,))
    sample_rates = torch.tensor([12000, 48000, 25600] * 5 + [12000])[:batch_size]

    # è¯¦ç»†å‰å‘ä¼ æ’­
    print("ğŸ”¬ é«˜çº§åŠŸèƒ½æµ‹è¯•...")

    with torch.no_grad():
        output = model(
            x,
            dataset_ids=dataset_ids,
            domain_ids=domain_ids,
            sample_rates=sample_rates
        )

        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"æ•°æ®é›†IDèŒƒå›´: {dataset_ids.min().item()}-{dataset_ids.max().item()}")
        print(f"åŸŸIDèŒƒå›´: {domain_ids.min().item()}-{domain_ids.max().item()}")
        print(f"é‡‡æ ·ç‡èŒƒå›´: {sample_rates.min().item()}-{sample_rates.max().item()}")

    # ç‰¹å¾å¯è§†åŒ–
    visualize_hse_features(output, dataset_ids)

    print("âœ… é«˜çº§ä½¿ç”¨æµ‹è¯•å®Œæˆï¼")

def visualize_hse_features(features, dataset_ids):
    """å¯è§†åŒ–HSEç‰¹å¾"""
    import matplotlib.pyplot as plt
    import seaborn as sns

    # è®¡ç®—ç‰¹å¾ç»Ÿè®¡
    feature_mean = features.mean(dim=1).detach().cpu().numpy()
    feature_std = features.std(dim=1).detach().cpu().numpy()

    # æŒ‰æ•°æ®é›†åˆ†ç»„
    unique_datasets = torch.unique(dataset_ids)

    plt.figure(figsize=(12, 8))

    for dataset_id in unique_datasets:
        mask = dataset_ids == dataset_id
        plt.scatter(
            feature_mean[mask, 0],
            feature_mean[mask, 1],
            label=f"Dataset {dataset_id.item()}",
            alpha=0.7
        )

    plt.xlabel("Feature Dimension 1")
    plt.ylabel("Feature Dimension 2")
    plt.title("HSE Features by Dataset")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
```

### 5.4 æœ€ä½³å®è·µ

#### æ€§èƒ½ä¼˜åŒ–æŠ€å·§
```python
class PerformanceOptimization:
    """æ€§èƒ½ä¼˜åŒ–æŠ€å·§"""

    @staticmethod
    def memory_efficient_forward(model, x, **kwargs):
        """å†…å­˜é«˜æ•ˆçš„å‰å‘ä¼ æ’­"""

        # æ¢¯åº¦æ£€æŸ¥ç‚¹
        from torch.utils.checkpoint import checkpoint

        def create_custom_forward(module):
            def custom_forward(*inputs):
                return module(*inputs)
            return custom_forward

        # å¯¹å¤§æ¨¡å—ä½¿ç”¨æ£€æŸ¥ç‚¹
        if hasattr(model, 'patch_embedding'):
            x = checkpoint(create_custom_forward(model.patch_embedding), x)

        if hasattr(model, 'prompt_encoder'):
            prompts = checkpoint(create_custom_forward(model.prompt_encoder), **kwargs)
        else:
            prompts = model.prompt_encoder(**kwargs)

        return model.fusion_layer(x, prompts)

    @staticmethod
    def mixed_precision_training(model, optimizer, data_loader):
        """æ··åˆç²¾åº¦è®­ç»ƒ"""
        from torch.cuda.amp import GradScaler, autocast

        scaler = GradScaler()

        for batch_idx, batch in enumerate(data_loader):
            optimizer.zero_grad()

            with autocast():
                output = model(batch['x'], **batch['metadata'])
                loss = compute_loss(output, batch['y'])

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            if batch_idx % 100 == 0:
                print(f"Batch {batch_idx}, Loss: {loss.item():.4f}")

    @staticmethod
    def batch_size_tuning(model, sample_input):
        """æ‰¹é‡å¤§å°è°ƒä¼˜"""
        device = next(model.parameters()).device

        # æµ‹è¯•ä¸åŒçš„æ‰¹é‡å¤§å°
        batch_sizes = [1, 2, 4, 8, 16, 32, 64]

        for batch_size in batch_sizes:
            try:
                # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
                test_batch = sample_input[:batch_size].to(device)

                # å†…å­˜ä½¿ç”¨æµ‹è¯•
                if torch.cuda.is_available():
                    torch.cuda.reset_peak_memory_stats()

                    with torch.no_grad():
                        output = model(test_batch)

                    memory_used = torch.cuda.max_memory_allocated() / 1024**2
                    print(f"âœ… Batch size {batch_size}: {memory_used:.1f} MB")

                else:
                    print(f"âœ… Batch size {batch_size}: OK")

            except RuntimeError as e:
                print(f"âŒ Batch size {batch_size}: OOM")
                break
```

---

## 6. é«˜çº§åŠŸèƒ½

### 6.1 é˜¶æ®µæ„ŸçŸ¥è®­ç»ƒ

#### Pretrainingé˜¶æ®µ
```python
def setup_pretraining_stage(model):
    """è®¾ç½®é¢„è®­ç»ƒé˜¶æ®µ"""

    # é…ç½®æ¨¡å‹çŠ¶æ€
    model.training_stage = "pretraining"

    # å¯ç”¨æ‰€æœ‰Promptè®­ç»ƒ
    for name, param in model.named_parameters():
        if 'prompt' in name.lower():
            param.requires_grad = True

    # è®¾ç½®å­¦ä¹ ç‡å€æ•°
    prompt_params = [p for n, p in model.named_parameters()
                    if 'prompt' in n.lower()]
    other_params = [p for n, p in model.named_parameters()
                   if 'prompt' not in n.lower()]

    return prompt_params, other_params

def pretraining_optimizer(model, base_lr=1e-4):
    """é¢„è®­ç»ƒé˜¶æ®µä¼˜åŒ–å™¨"""
    prompt_params, other_params = setup_pretraining_stage(model)

    optimizer = torch.optim.AdamW([
        {'params': other_params, 'lr': base_lr},
        {'params': prompt_params, 'lr': base_lr * 0.1}  # Promptå­¦ä¹ ç‡è¾ƒä½
    ], weight_decay=1e-4)

    return optimizer
```

#### Finetuneé˜¶æ®µ
```python
def setup_finetune_stage(model, freeze_prompts=True):
    """è®¾ç½®å¾®è°ƒé˜¶æ®µ"""

    model.training_stage = "finetune"

    if freeze_prompts:
        # å†»ç»“Promptå‚æ•°
        for name, param in model.named_parameters():
            if 'prompt' in name.lower():
                param.requires_grad = False

    # è¿”å›å¯è®­ç»ƒå‚æ•°
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    return trainable_params

def finetune_optimizer(model, base_lr=5e-5):
    """å¾®è°ƒé˜¶æ®µä¼˜åŒ–å™¨"""
    trainable_params = setup_finetune_stage(model, freeze_prompts=True)

    optimizer = torch.optim.AdamW(
        trainable_params,
        lr=base_lr,
        weight_decay=1e-5
    )

    return optimizer
```

### 6.2 å†…å­˜ä¼˜åŒ–æŠ€å·§

#### æ¢¯åº¦ç´¯ç§¯
```python
def gradient_accumulation_training(model, data_loader, accumulation_steps=4):
    """æ¢¯åº¦ç´¯ç§¯è®­ç»ƒ"""

    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    scaler = torch.cuda.amp.GradScaler()

    model.train()

    for batch_idx, batch in enumerate(data_loader):
        # å‰å‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
        with torch.cuda.amp.autocast():
            output = model(batch['x'], **batch['metadata'])
            loss = compute_loss(output, batch['y']) / accumulation_steps

        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()

        # æ¢¯åº¦ç´¯ç§¯
        if (batch_idx + 1) % accumulation_steps == 0:
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
```

#### ç‰¹å¾ç¼“å­˜
```python
class FeatureCache:
    """ç‰¹å¾ç¼“å­˜æœºåˆ¶"""

    def __init__(self, max_cache_size=1000):
        self.cache = {}
        self.max_cache_size = max_cache_size

    def get_or_compute(self, model, x, cache_key=None):
        """è·å–æˆ–è®¡ç®—ç‰¹å¾"""

        if cache_key is None:
            # ä½¿ç”¨è¾“å…¥å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
            cache_key = hash(x.data_ptr())

        if cache_key in self.cache:
            return self.cache[cache_key]

        # è®¡ç®—ç‰¹å¾
        with torch.no_grad():
            features = model(x)

        # ç¼“å­˜ç®¡ç†
        if len(self.cache) >= self.max_cache_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        self.cache[cache_key] = features
        return features
```

### 6.3 è‡ªå®šä¹‰æ‰©å±•

#### è‡ªå®šä¹‰èåˆç­–ç•¥
```python
class CustomFusionStrategy(nn.Module):
    """è‡ªå®šä¹‰èåˆç­–ç•¥ç¤ºä¾‹"""

    def __init__(self, feature_dim, prompt_dim):
        super().__init__()

        # è‡ªå®šä¹‰èåˆç½‘ç»œ
        self.fusion_network = nn.Sequential(
            nn.Linear(feature_dim + prompt_dim, feature_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(feature_dim * 2, feature_dim),
            nn.LayerNorm(feature_dim)
        )

        # æ³¨æ„åŠ›æƒé‡
        self.attention_weights = nn.Parameter(torch.ones(2))

    def forward(self, hse_features, prompts):
        """è‡ªå®šä¹‰èåˆé€»è¾‘"""

        # æ‰©å±•promptsåˆ°è¡¥ä¸ç»´åº¦
        prompts_expanded = prompts.unsqueeze(1).expand(-1, hse_features.size(1), -1)

        # æ‹¼æ¥ç‰¹å¾
        concatenated = torch.cat([hse_features, prompts_expanded], dim=-1)

        # èåˆç½‘ç»œå¤„ç†
        fused_features = self.fusion_network(concatenated)

        # åŠ æƒèåˆ
        weights = F.softmax(self.attention_weights, dim=0)
        final_features = weights[0] * hse_features + weights[1] * fused_features

        return final_features

# æ³¨å†Œè‡ªå®šä¹‰èåˆç­–ç•¥
def register_custom_fusion(model, fusion_strategy="custom"):
    """æ³¨å†Œè‡ªå®šä¹‰èåˆç­–ç•¥åˆ°æ¨¡å‹"""
    if hasattr(model, 'fusion_layer'):
        model.fusion_layer = CustomFusionStrategy(
            model.output_dim,
            model.prompt_dim
        )
        model.fusion_type = fusion_strategy

    return model
```

#### è‡ªå®šä¹‰Promptç¼–ç å™¨
```python
class CustomPromptEncoder(nn.Module):
    """è‡ªå®šä¹‰Promptç¼–ç å™¨"""

    def __init__(self, num_datasets, prompt_dim, encoder_type="transformer"):
        super().__init__()

        self.num_datasets = num_datasets
        self.prompt_dim = prompt_dim
        self.encoder_type = encoder_type

        if encoder_type == "transformer":
            # Transformerç¼–ç å™¨
            self.embedding = nn.Embedding(num_datasets, prompt_dim)
            self.transformer = nn.TransformerEncoder(
                nn.TransformerEncoderLayer(
                    d_model=prompt_dim,
                    nhead=8,
                    dim_feedforward=prompt_dim * 4,
                    dropout=0.1,
                    batch_first=True
                ),
                num_layers=2
            )

        elif encoder_type == "mlp":
            # MLPç¼–ç å™¨
            self.embedding = nn.Embedding(num_datasets, prompt_dim // 4)
            self.mlp = nn.Sequential(
                nn.Linear(prompt_dim // 4, prompt_dim // 2),
                nn.ReLU(),
                nn.Linear(prompt_dim // 2, prompt_dim)
            )

        elif encoder_type == "lstm":
            # LSTMç¼–ç å™¨
            self.embedding = nn.Embedding(num_datasets, prompt_dim // 2)
            self.lstm = nn.LSTM(prompt_dim // 2, prompt_dim // 2,
                               batch_first=True, bidirectional=True)

    def forward(self, dataset_ids):
        """å‰å‘ä¼ æ’­"""

        # åŸºç¡€åµŒå…¥
        embedded = self.embedding(dataset_ids)

        if self.encoder_type == "transformer":
            # Transformerç¼–ç 
            embedded = embedded.unsqueeze(1)  # [B, 1, D]
            encoded = self.transformer(embedded)
            return encoded.squeeze(1)

        elif self.encoder_type == "mlp":
            # MLPç¼–ç 
            return self.mlp(embedded)

        elif self.encoder_type == "lstm":
            # LSTMç¼–ç 
            embedded = embedded.unsqueeze(1)
            lstm_out, _ = self.lstm(embedded)
            return lstm_out.squeeze(1)
```

### 6.4 è°ƒè¯•å’ŒéªŒè¯

#### ç‰¹å¾å¯è§†åŒ–å·¥å…·
```python
class HSEFeatureVisualizer:
    """HSEç‰¹å¾å¯è§†åŒ–å·¥å…·"""

    def __init__(self, model):
        self.model = model

    def extract_features(self, data_loader, num_samples=1000):
        """æå–ç‰¹å¾"""
        self.model.eval()
        features = []
        labels = []
        dataset_ids = []

        with torch.no_grad():
            for batch_idx, batch in enumerate(data_loader):
                if len(features) >= num_samples:
                    break

                output = self.model(batch['x'], **batch['metadata'])

                # ä½¿ç”¨å¹³å‡æ± åŒ–å¾—åˆ°æ ·æœ¬çº§ç‰¹å¾
                sample_features = output.mean(dim=1)  # [B, D]

                features.append(sample_features.cpu())
                labels.append(batch['y'].cpu())
                dataset_ids.append(batch['metadata']['dataset_ids'].cpu())

        return torch.cat(features), torch.cat(labels), torch.cat(dataset_ids)

    def visualize_tsne(self, features, labels, dataset_ids):
        """t-SNEå¯è§†åŒ–"""
        from sklearn.manifold import TSNE
        import matplotlib.pyplot as plt

        # t-SNEé™ç»´
        tsne = TSNE(n_components=2, random_state=42)
        features_2d = tsne.fit_transform(features.numpy())

        # å¯è§†åŒ–
        plt.figure(figsize=(15, 5))

        # æŒ‰ç±»åˆ«ç€è‰²
        plt.subplot(1, 3, 1)
        scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1],
                            c=labels.numpy(), cmap='tab10', alpha=0.7)
        plt.colorbar(scatter)
        plt.title("Features by Class")
        plt.xlabel("t-SNE 1")
        plt.ylabel("t-SNE 2")

        # æŒ‰æ•°æ®é›†ç€è‰²
        plt.subplot(1, 3, 2)
        scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1],
                            c=dataset_ids.numpy(), cmap='Set1', alpha=0.7)
        plt.colorbar(scatter)
        plt.title("Features by Dataset")
        plt.xlabel("t-SNE 1")
        plt.ylabel("t-SNE 2")

        # ç»„åˆä¿¡æ¯
        plt.subplot(1, 3, 3)
        for dataset_id in torch.unique(dataset_ids):
            mask = dataset_ids == dataset_id
            for label in torch.unique(labels):
                mask2 = (dataset_ids == dataset_id) & (labels == label)
                if mask2.any():
                    plt.scatter(features_2d[mask2, 0], features_2d[mask2, 1],
                              label=f"D{dataset_id.item()}_C{label.item()}",
                              alpha=0.7)

        plt.title("Features by Dataset+Class")
        plt.xlabel("t-SNE 1")
        plt.ylabel("t-SNE 2")
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

        plt.tight_layout()
        plt.show()

    def plot_attention_weights(self, model, x, dataset_ids):
        """ç»˜åˆ¶æ³¨æ„åŠ›æƒé‡"""
        if hasattr(model, 'fusion_layer') and hasattr(model.fusion_layer, 'attention'):

            # è·å–æ³¨æ„åŠ›æƒé‡
            with torch.no_grad():
                model.eval()
                output = model(x, dataset_ids=dataset_ids, return_attention=True)
                attention_weights = output['attention']  # [B, num_heads, seq_len, seq_len]

            # å¯è§†åŒ–æ³¨æ„åŠ›
            num_heads = attention_weights.size(1)
            fig, axes = plt.subplots(2, num_heads//2, figsize=(15, 8))
            axes = axes.flatten()

            for head_idx in range(num_heads):
                ax = axes[head_idx]
                im = ax.imshow(attention_weights[0, head_idx].cpu(), cmap='Blues')
                ax.set_title(f"Head {head_idx}")
                ax.set_xlabel("Key Position")
                ax.set_ylabel("Query Position")
                plt.colorbar(im, ax=ax)

            plt.suptitle("Attention Weights Visualization")
            plt.tight_layout()
            plt.show()
```

---

## 7. æ•…éšœæ’é™¤

### 7.1 å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### å†…å­˜ç›¸å…³é”™è¯¯

| é”™è¯¯ç±»å‹ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|
| `CUDA out of memory` | æ‰¹æ¬¡å¤ªå¤§æˆ–æ¨¡å‹å¤ªå¤§ | å‡å°batch_sizeã€ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ··åˆç²¾åº¦è®­ç»ƒ |
| `RuntimeError: mat1 and mat2 shapes cannot be multiplied` | ç»´åº¦ä¸åŒ¹é… | æ£€æŸ¥prompt_dimå’Œoutput_dimé…ç½® |
| `IndexError: index out of range in self` | dataset_idè¶…å‡ºèŒƒå›´ | å¢åŠ max_dataset_idså‚æ•°æˆ–æ£€æŸ¥æ•°æ® |

#### é…ç½®é”™è¯¯

| é…ç½®é—®é¢˜ | é”™è¯¯ç°è±¡ | ä¿®å¤æ–¹æ³• |
|----------|----------|----------|
| `fusion_type`é”™è¯¯ | `KeyError: 'unknown_fusion'` | ä½¿ç”¨æ”¯æŒçš„èåˆç±»å‹ï¼šattention/gating/concat |
| `prompt_dim`ä¸åŒ¹é… | çŸ©é˜µä¹˜æ³•ç»´åº¦é”™è¯¯ | ç¡®ä¿prompt_dimä¸æ¨¡å‹å…¶ä»–ç»„ä»¶å…¼å®¹ |
| `max_dataset_ids`å¤ªå° | ç´¢å¼•è¶Šç•Œé”™è¯¯ | è®¾ç½®ä¸ºæ¯”å®é™…æ•°æ®é›†æ•°é‡å¤§çš„å€¼ |

#### è®­ç»ƒé—®é¢˜

| è®­ç»ƒé—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|----------|----------|----------|
| æŸå¤±ä¸ä¸‹é™ | Promptå†»ç»“æˆ–å­¦ä¹ ç‡å¤ªå° | æ£€æŸ¥freeze_promptsè®¾ç½®ï¼Œè°ƒæ•´prompt_lr_multiplier |
| æ”¶æ•›å¾ˆæ…¢ | å¤æ‚èåˆç­–ç•¥è¿‡æ‹Ÿåˆ | ç®€åŒ–èåˆç­–ç•¥æˆ–å¢åŠ æ­£åˆ™åŒ– |
| è¿‡æ‹Ÿåˆ | Promptè¿‡æ‹Ÿåˆ | å¢åŠ dropoutï¼Œä½¿ç”¨æ—©åœï¼Œå‡å°prompt_dim |

### 7.2 è°ƒè¯•å·¥å…·

#### æ¨¡å‹çŠ¶æ€æ£€æŸ¥å™¨
```python
class HSEModelChecker:
    """HSEæ¨¡å‹çŠ¶æ€æ£€æŸ¥å™¨"""

    @staticmethod
    def check_model_configuration(model):
        """æ£€æŸ¥æ¨¡å‹é…ç½®"""
        print("ğŸ” æ¨¡å‹é…ç½®æ£€æŸ¥:")

        # æ£€æŸ¥å…³é”®å±æ€§
        required_attrs = ['patch_size_L', 'num_patches', 'output_dim', 'prompt_dim']
        for attr in required_attrs:
            if hasattr(model, attr):
                print(f"  âœ… {attr}: {getattr(model, attr)}")
            else:
                print(f"  âŒ {attr}: ç¼ºå¤±")

        # æ£€æŸ¥ç»„ä»¶
        components = ['patch_embedding', 'prompt_encoder', 'fusion_layer']
        for comp in components:
            if hasattr(model, comp):
                print(f"  âœ… {comp}: {type(getattr(model, comp)).__name__}")
            else:
                print(f"  âŒ {comp}: ç¼ºå¤±")

    @staticmethod
    def check_tensor_shapes(model, input_shape):
        """æ£€æŸ¥å¼ é‡å½¢çŠ¶"""
        print("\nğŸ“Š å¼ é‡å½¢çŠ¶æ£€æŸ¥:")

        try:
            with torch.no_grad():
                x = torch.randn(input_shape)
                dataset_ids = torch.randint(0, 10, (input_shape[0],))

                output = model(x, dataset_ids=dataset_ids)

                print(f"  è¾“å…¥å½¢çŠ¶: {x.shape}")
                print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")

                # æ£€æŸ¥ä¸­é—´å±‚å½¢çŠ¶
                if hasattr(model, 'patch_embedding'):
                    patches = model.patch_embedding(x)
                    print(f"  è¡¥ä¸å½¢çŠ¶: {patches.shape}")

                if hasattr(model, 'prompt_encoder'):
                    prompts = model.prompt_encoder(dataset_ids)
                    print(f"  Promptå½¢çŠ¶: {prompts.shape}")

        except Exception as e:
            print(f"  âŒ å½¢çŠ¶æ£€æŸ¥å¤±è´¥: {e}")

    @staticmethod
    def check_gradients(model):
        """æ£€æŸ¥æ¢¯åº¦"""
        print("\nğŸ”„ æ¢¯åº¦æ£€æŸ¥:")

        total_params = 0
        trainable_params = 0
        zero_grad_params = 0

        for name, param in model.named_parameters():
            total_params += param.numel()

            if param.requires_grad:
                trainable_params += param.numel()

                if param.grad is not None:
                    grad_norm = param.grad.norm().item()
                    if grad_norm < 1e-8:
                        zero_grad_params += param.numel()
                        print(f"  âš ï¸  {name}: æ¢¯åº¦è¿‡å° ({grad_norm:.2e})")
                    elif grad_norm > 10:
                        print(f"  âš ï¸  {name}: æ¢¯åº¦è¿‡å¤§ ({grad_norm:.2f})")
                else:
                    print(f"  âŒ {name}: æ— æ¢¯åº¦")

        print(f"  æ€»å‚æ•°: {total_params:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"  æ¢¯åº¦è¿‡å°å‚æ•°: {zero_grad_params:,}")
```

#### æ€§èƒ½åˆ†æå™¨
```python
class HSEProfiler:
    """HSEæ€§èƒ½åˆ†æå™¨"""

    def __init__(self, model):
        self.model = model

    def profile_forward_pass(self, input_shape, num_runs=100):
        """åˆ†æå‰å‘ä¼ æ’­æ€§èƒ½"""
        import time

        self.model.eval()

        # é¢„çƒ­
        x = torch.randn(input_shape)
        dataset_ids = torch.randint(0, 10, (input_shape[0],))

        with torch.no_grad():
            for _ in range(10):
                _ = self.model(x, dataset_ids=dataset_ids)

        # è®¡æ—¶
        if torch.cuda.is_available():
            torch.cuda.synchronize()

        start_time = time.time()

        with torch.no_grad():
            for _ in range(num_runs):
                output = self.model(x, dataset_ids=dataset_ids)

        if torch.cuda.is_available():
            torch.cuda.synchronize()

        end_time = time.time()

        avg_time = (end_time - start_time) / num_runs
        throughput = input_shape[0] / avg_time

        print(f"â±ï¸  æ€§èƒ½åˆ†æç»“æœ:")
        print(f"  å¹³å‡å‰å‘ä¼ æ’­æ—¶é—´: {avg_time*1000:.2f} ms")
        print(f"  ååé‡: {throughput:.1f} samples/second")
        print(f"  è¾“å…¥å½¢çŠ¶: {input_shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")

    def memory_usage_analysis(self, input_shape, batch_sizes):
        """å†…å­˜ä½¿ç”¨åˆ†æ"""
        print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨åˆ†æ:")

        for batch_size in batch_sizes:
            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.reset_peak_memory_stats()

                    # æµ‹è¯•å†…å­˜ä½¿ç”¨
                    x = torch.randn(batch_size, *input_shape[1:]).cuda()
                    dataset_ids = torch.randint(0, 10, (batch_size,)).cuda()

                    self.model = self.model.cuda()

                    with torch.no_grad():
                        output = self.model(x, dataset_ids=dataset_ids)

                    memory_used = torch.cuda.max_memory_allocated() / 1024**2
                    print(f"  Batch size {batch_size}: {memory_used:.1f} MB")

                    self.model = self.model.cpu()
                    torch.cuda.empty_cache()

            except RuntimeError as e:
                print(f"  Batch size {batch_size}: OOM - {e}")
                break
```

### 7.3 æœ€ä½³å®è·µå»ºè®®

#### å¼€å‘å»ºè®®

1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆç”¨HSE_promptéªŒè¯æƒ³æ³•ï¼Œå†å‡çº§åˆ°E_01_HSE_v2
2. **é€æ­¥è°ƒè¯•**ï¼šå…ˆæµ‹è¯•å•ä¸ªç»„ä»¶ï¼Œå†é›†æˆå®Œæ•´ç³»ç»Ÿ
3. **å¯è§†åŒ–æ£€æŸ¥**ï¼šä½¿ç”¨ç‰¹å¾å¯è§†åŒ–éªŒè¯æ¨¡å‹è¡Œä¸º
4. **åŸºå‡†æµ‹è¯•**ï¼šå»ºç«‹æ€§èƒ½åŸºçº¿ï¼Œè·Ÿè¸ªæ”¹è¿›æ•ˆæœ

#### éƒ¨ç½²å»ºè®®

1. **é…ç½®ç®¡ç†**ï¼šä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†é…ç½®æ–‡ä»¶
2. **ç¯å¢ƒéš”ç¦»**ï¼šä¸ºä¸åŒå®éªŒåˆ›å»ºç‹¬ç«‹ç¯å¢ƒ
3. **æ—¥å¿—è®°å½•**ï¼šè¯¦ç»†è®°å½•è®­ç»ƒè¿‡ç¨‹å’Œè¶…å‚æ•°
4. **æ¨¡å‹æ£€æŸ¥ç‚¹**ï¼šå®šæœŸä¿å­˜æ¨¡å‹çŠ¶æ€

#### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å†…å­˜ä¼˜åŒ–**ï¼šä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹å’Œæ··åˆç²¾åº¦è®­ç»ƒ
2. **è®¡ç®—ä¼˜åŒ–**ï¼šåˆç†è®¾ç½®batch_sizeå’Œnum_workers
3. **IOä¼˜åŒ–**ï¼šä½¿ç”¨é«˜æ•ˆçš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
4. **æ¨¡å‹å‹ç¼©**ï¼šè€ƒè™‘æ¨¡å‹å‰ªæå’Œé‡åŒ–

---

## æ€»ç»“

ISFM_PromptåµŒå…¥ç»„ä»¶æä¾›äº†ä¸¤ç§ä¸åŒå¤æ‚åº¦çš„HSEå®ç°ï¼š

- **E_01_HSE_v2**ï¼šé€‚åˆç ”ç©¶çº§åº”ç”¨ï¼Œæä¾›ä¸°å¯Œçš„åŠŸèƒ½å’Œä¼˜ç§€çš„æ€§èƒ½
- **HSE_prompt**ï¼šé€‚åˆæ•™è‚²å’Œå¿«é€ŸåŸå‹ï¼Œæä¾›ç®€æ´é«˜æ•ˆçš„å®ç°

é€‰æ‹©åˆé€‚çš„å®ç°éœ€è¦è€ƒè™‘å…·ä½“çš„åº”ç”¨åœºæ™¯ã€è®¡ç®—èµ„æºå’Œå¼€å‘éœ€æ±‚ã€‚æœ¬æ–‡æ¡£æä¾›äº†å…¨é¢çš„æŠ€æœ¯æŒ‡å¯¼ï¼Œå¸®åŠ©ç”¨æˆ·åšå‡ºæœ€ä½³é€‰æ‹©å¹¶æˆåŠŸé›†æˆåˆ°å®é™…é¡¹ç›®ä¸­ã€‚
