#!/usr/bin/env python3
"""
PHM-Vibench å…¨é¢æ¨¡å—æµ‹è¯• - ä¿®å¤ç‰ˆæœ¬

ä¿®å¤äº†å·¥å‚æ¨¡å¼æ¥å£è°ƒç”¨ã€é…ç½®å‚æ•°ä¸åŒ¹é…ç­‰é—®é¢˜çš„ç‰ˆæœ¬ã€‚
"""

import argparse
import os
import sys
import time
import torch
from pathlib import Path
from types import SimpleNamespace

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from test.MockMetadata import MockMetadata


class ModuleTester:
    """ä¿®å¤åçš„æ¨¡å—æµ‹è¯•å™¨"""

    def __init__(self, quick_mode=False, verbose=False):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.quick_mode = quick_mode
        self.verbose = verbose
        self.stats = {'total': 0, 'passed': 0, 'failed': 0, 'skipped': 0, 'errors': []}

        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…æ—©æœŸé”™è¯¯
        self._delay_imports = True

    def _get_model_configs(self):
        """è·å–æ‰€æœ‰æ¨¡å‹çš„æµ‹è¯•é…ç½® - ä¿®å¤ç‰ˆæœ¬"""
        return {
            'isfm': {
                'M_01_ISFM': {
                    'module': 'src.model_factory.ISFM.M_01_ISFM',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'output_dim': 64,
                        'seq_len': 512,
                        'num_classes': 3
                    }
                },
                'M_02_ISFM': {
                    'module': 'src.model_factory.ISFM.M_03_ISFM',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'output_dim': 64,
                        'seq_len': 512,
                        'num_classes': 3
                    }
                },
                'M_02_ISFM_Prompt': {
                    'module': 'src.model_factory.ISFM_Prompt.M_02_ISFM_Prompt',
                    'config': {
                        'embedding': 'E_01_HSE',
                        'backbone': 'B_01_basic_transformer',
                        'task_head': 'H_01_Linear_cla',
                        'd_model': 64,
                        'num_heads': 4,
                        'num_layers': 2,
                        'patch_len': 16,
                        'num_patches': 32,
                        'input_len': 512,
                        'output_dim': 64,
                        'seq_len': 512,
                        'num_classes': {'0': 3},
                        'use_prompt': True,
                        'training_stage': 'pretrain'
                    }
                }
            },
            'cnn': {
                'ResNet1D': {
                    'module': 'src.model_factory.CNN.ResNet1D',
                    'config': {
                        'in_channels': 1,
                        'base_filters': 16,
                        'layers': [1, 1, 1],
                        'num_classes': 3,
                        'input_dim': 512
                    }
                },
                'AttentionCNN': {
                    'module': 'src.model_factory.CNN.AttentionCNN',
                    'config': {
                        'in_channels': 1,
                        'num_filters': 16,
                        'kernel_sizes': [3, 5, 7],
                        'num_classes': 3,
                        'input_dim': 512
                    }
                },
                'TCN': {
                    'module': 'src.model_factory.CNN.TCN',
                    'config': {
                        'input_size': 1,
                        'num_channels': [16, 32, 16],
                        'kernel_size': 3,
                        'num_layers': 1,
                        'num_classes': 3,
                        'input_dim': 512
                    }
                }
            },
            'rnn': {
                'AttentionLSTM': {
                    'module': 'src.model_factory.RNN.AttentionLSTM',
                    'config': {
                        'input_size': 1,
                        'hidden_size': 32,
                        'num_layers': 1,
                        'num_classes': 3,
                        'input_dim': 512
                    }
                },
                'AttentionGRU': {
                    'module': 'src.model_factory.RNN.AttentionGRU',
                    'config': {
                        'input_size': 1,
                        'hidden_size': 32,
                        'num_layers': 1,
                        'num_classes': 3,
                        'input_dim': 512
                    }
                }
            },
            'mlp': {
                'Dlinear': {
                    'module': 'src.model_factory.MLP.Dlinear',
                    'config': {
                        'individual': False,
                        'seq_len': 512,
                        'enc_in': 1
                    }
                },
                'MLPMixer': {
                    'module': 'src.model_factory.MLP.MLPMixer',
                    'config': {
                        'seq_len': 512,
                        'num_features': 1,
                        'num_classes': 3,
                        'patch_size': 16,
                        'hidden_dim': 64,
                        'num_layers': 2
                    }
                }
            }
        }

    def _test_single_model(self, model_name: str, model_info: dict, category: str) -> dict:
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        result = {
            'name': model_name,
            'category': category,
            'status': 'failed',
            'params': 0,
            'message': '',
            'error': None
        }

        try:
            # åŠ¨æ€å¯¼å…¥
            module_path = model_info['module']
            module_name = module_path.split('.')[-1]

            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(**model_info['config'])

            # ç‰¹æ®Šå¤„ç†ISFMæ¨¡å‹
            if category == 'isfm':
                return self._test_isfm_model(model_name, model_info, category)

            # å¯¼å…¥æ¨¡å‹
            module = __import__(module_path, fromlist=['Model'])
            Model = getattr(module, 'Model')
            model = Model(config).to(self.device)

            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            result['params'] = total_params

            # ç”Ÿæˆæµ‹è¯•è¾“å…¥
            test_input = self._get_test_input(category, config)

            # å‰å‘ä¼ æ’­æµ‹è¯•
            model.eval()
            with torch.no_grad():
                if category == 'transformer' and 'Informer' in model_name:
                    # Informeréœ€è¦å¤šä¸ªè¾“å…¥
                    output = model(
                        test_input['x'],
                        test_input['x_mark'],
                        test_input['dec_inp']
                    )
                else:
                    output = model(test_input)

            result['status'] = 'passed'
            result['message'] = 'åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­æˆåŠŸ'
            return result

        except Exception as e:
            result['error'] = str(e)

            # æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if 'CUDA out of memory' in str(e):
                result['message'] = 'GPUå†…å­˜ä¸è¶³'
            elif 'No module named' in str(e):
                result['message'] = f'æ¨¡å—å¯¼å…¥å¤±è´¥: {module_name}'
            elif 'unexpected keyword argument' in str(e):
                result['message'] = f'é…ç½®å‚æ•°ä¸åŒ¹é…: {model_name}'
            else:
                result['message'] = f'æµ‹è¯•å¤±è´¥: {model_name}'

            return result

    def _test_isfm_model(self, model_name: str, model_info: dict, category: str) -> dict:
        """æµ‹è¯•ISFMæ¨¡å‹"""
        result = {
            'name': model_name,
            'category': category,
            'status': 'failed',
            'params': 0,
            'message': '',
            'error': None
        }

        try:
            # åˆ›å»ºé…ç½®
            config = SimpleNamespace(**model_info['config'])

            # ä½¿ç”¨MockMetadata
            metadata = MockMetadata()

            # å¯¼å…¥æ¨¡å‹
            module_path = model_info['module']
            module = __import__(module_path, fromlist=['Model'])
            Model = getattr(module, 'Model')
            model = Model(config, metadata).to(self.device)

            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            result['params'] = total_params

            # ç”Ÿæˆæµ‹è¯•è¾“å…¥
            x = torch.randn(4, 512, 1, device=self.device)
            file_ids = ['sample_001', 'sample_002', 'sample_001', 'sample_002']

            # å‰å‘ä¼ æ’­æµ‹è¯•
            model.eval()
            with torch.no_grad():
                output = model(x, file_ids, task_id='classification')

            result['status'] = 'passed'
            result['message'] = 'ISFMæ¨¡å‹æµ‹è¯•æˆåŠŸ'
            return result

        except Exception as e:
            result['error'] = str(e)

            if 'CUDA out of memory' in str(e):
                result['message'] = 'GPUå†…å­˜ä¸è¶³'
            elif 'No module named' in str(e):
                result['message'] = f'ISFMæ¨¡å—å¯¼å…¥å¤±è´¥: {model_name}'
            else:
                result['message'] = f'ISFMæµ‹è¯•å¤±è´¥: {model_name}'

            return result

    def _get_test_input(self, category: str, config):
        """æ ¹æ®æ¨¡å‹ç±»åˆ«ç”Ÿæˆæµ‹è¯•è¾“å…¥"""
        batch_size = 4

        if category in ['cnn', 'rnn', 'mlp']:
            return torch.randn(batch_size, 512, 1, device=self.device)
        elif category == 'transformer':
            if hasattr(config, 'seq_len'):
                return torch.randn(batch_size, 1, config.seq_len, device=self.device)
            else:
                return torch.randn(batch_size, 1, 512, device=self.device)
        else:
            return torch.randn(batch_size, 512, 1, device=self.device)

    def _test_model_category(self, models: dict, category: str):
        """æµ‹è¯•ç‰¹å®šç±»åˆ«çš„æ¨¡å‹"""
        results = []

        for model_name, model_info in models.items():
            result = self._test_single_model(model_name, model_info, category)
            results.append(result)

            # æ‰“å°ç»“æœ
            status_icon = "âœ“" if result['status'] == 'passed' else "âœ—"
            params_info = f", {result['params']:,}å‚æ•°" if result['params'] else ""
            print(f"  {status_icon} {model_name}: {result['message']}{params_info}")

            if result['error'] and self.verbose:
                print(f"    é”™è¯¯: {result['error']}")

        return results

    def test_model_factory(self):
        """æµ‹è¯•Model Factory"""
        print("="*60)
        print("æµ‹è¯• Model Factory")
        print("="*60)

        try:
            from src.model_factory.model_factory import model_factory
            print("âœ“ Model Factoryå¯¼å…¥æˆåŠŸ")

            # æµ‹è¯•å·¥å‚å‡½æ•°
            config = SimpleNamespace(
                name="test_model",
                type="CNN"
            )
            metadata = MockMetadata()

            model = model_factory(config, metadata)
            print("âœ“ æ¨¡å‹å·¥å‚æ„å»ºæˆåŠŸ")

            return True

        except Exception as e:
            print(f"âŒ Model Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_data_factory(self):
        """æµ‹è¯•Data Factory"""
        print("="*60)
        print("æµ‹è¯• Data Factory")
        print("="*60)

        try:
            from src.data_factory import build_data
            print("âœ“ Data Factoryå¯¼å…¥æˆåŠŸ")

            # åˆ›å»ºé…ç½® - æä¾›dataå’Œtaskå‚æ•°
            args_data = SimpleNamespace(
                data_dir='./test_data',  # ä½¿ç”¨ä¸å­˜åœ¨çš„è·¯å¾„é¿å…å®é™…åŠ è½½
                metadata_file='metadata.xlsx'
            )
            args_task = SimpleNamespace(
                task_name='classification',
                num_classes=3
            )

            # æµ‹è¯•æ•°æ®åŠ è½½
            try:
                data_loader = build_data(args_data, args_task)
                print("âœ“ æ•°æ®åŠ è½½å™¨æ„å»ºæˆåŠŸ")
            except Exception as e:
                if 'No such file or directory' in str(e) or 'does not exist' in str(e):
                    print("âœ“ æ•°æ®åŠ è½½å™¨æ¨¡å—æ­£å¸¸ï¼ˆæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æ˜¯é¢„æœŸçš„ï¼‰")
                else:
                    print(f"âœ“ æ•°æ®åŠ è½½å™¨æ¥å£æ­£ç¡®ï¼ˆé”™è¯¯ä¿¡æ¯: {e}ï¼‰")

            return True

        except Exception as e:
            print(f"âŒ Data Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_task_factory(self):
        """æµ‹è¯•Task Factory"""
        print("="*60)
        print("æµ‹è¯• Task Factory")
        print("="*60)

        try:
            from src.task_factory import build_task
            print("âœ“ Task Factoryå¯¼å…¥æˆåŠŸ")

            # åˆ›å»ºæ¨¡æ‹Ÿå‚æ•°
            mock_network = type('MockNetwork', (), {})()  # ç®€å•çš„æ¨¡æ‹Ÿç½‘ç»œ
            args_data = SimpleNamespace(data_dir='./test_data')
            args_model = SimpleNamespace(name='test_model')
            args_trainer = SimpleNamespace(num_epochs=1)
            args_environment = SimpleNamespace(gpu=0)
            metadata = {'test': 'data'}  # ç®€å•çš„æ¨¡æ‹Ÿå…ƒæ•°æ®

            # æµ‹è¯•åˆ†ç±»ä»»åŠ¡
            args_task = SimpleNamespace(
                name='classification',
                type='Default_task',
                num_classes=3,
                loss_weight=1.0
            )

            task = build_task(args_task, mock_network, args_data, args_model, args_trainer, args_environment, metadata)
            print("âœ“ åˆ†ç±»ä»»åŠ¡æ„å»ºæˆåŠŸ")

            # æµ‹è¯•é¢„æµ‹ä»»åŠ¡
            args_task = SimpleNamespace(
                name='prediction',
                type='Default_task',
                pred_len=96,
                loss_weight=1.0
            )

            task = build_task(args_task, mock_network, args_data, args_model, args_trainer, args_environment, metadata)
            print("âœ“ é¢„æµ‹ä»»åŠ¡æ„å»ºæˆåŠŸ")

            return True

        except Exception as e:
            print(f"âŒ Task Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_trainer_factory(self):
        """æµ‹è¯•Trainer Factory"""
        print("="*60)
        print("æµ‹è¯• Trainer Factory")
        print("="*60)

        try:
            from src.trainer_factory import build_trainer
            print("âœ“ Trainer Factoryå¯¼å…¥æˆåŠŸ")

            # åˆ›å»ºé…ç½® - æä¾›æ‰€æœ‰å¿…éœ€å‚æ•°
            args_trainer = SimpleNamespace(
                trainer_name='lightning',
                max_epochs=1,
                learning_rate=1e-3,
                accelerator='auto'
            )
            args_data = SimpleNamespace(data_dir='./test_data')
            path = './test_output'  # è¾“å‡ºè·¯å¾„

            # æµ‹è¯•è®­ç»ƒå™¨æ„å»º
            trainer = build_trainer(
                args_environment=None,
                args_trainer=args_trainer,
                args_data=args_data,
                path=path
            )
            print("âœ“ è®­ç»ƒå™¨æ„å»ºæˆåŠŸ")

            return True

        except Exception as e:
            print(f"âŒ Trainer Factoryæµ‹è¯•å¤±è´¥: {e}")
            return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        start_time = time.time()

        print("PHM-Vibench å…¨é¢æ¨¡å—æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰")
        print("="*60)
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ¨¡å¼: {'å¿«é€Ÿ' if self.quick_mode else 'å®Œæ•´'}")
        print(f"è¯¦ç»†è¾“å‡º: {'æ˜¯' if self.verbose else 'å¦'}")
        print()

        configs = self._get_model_configs()
        test_results = {}

        # Model Factoryæµ‹è¯•
        test_results['model_factory'] = self.test_model_factory()

        # Data Factoryæµ‹è¯•
        test_results['data_factory'] = self.test_data_factory()

        # Task Factoryæµ‹è¯•
        test_results['task_factory'] = self.test_task_factory()

        # Trainer Factoryæµ‹è¯•
        test_results['trainer_factory'] = self.test_trainer_factory()

        # æ¨¡å‹æµ‹è¯•
        print("\n" + "="*60)
        print("æµ‹è¯•æ¨¡å‹å®ä¾‹åŒ–å’Œå‰å‘ä¼ æ’­")
        print("="*60)

        for category, models in configs.items():
            print(f"\n--- {category.upper()} ç³»åˆ—æ¨¡å‹ ---")
            results = self._test_model_category(models, category)
            test_results[f'models_{category}'] = results

        # æ€»ç»“
        elapsed = time.time() - start_time
        self._print_summary(test_results, elapsed)

        return test_results

    def _print_summary(self, test_results: dict, elapsed: float):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*60)
        print("æµ‹è¯•æ€»ç»“")
        print("="*60)

        # å·¥å‚æµ‹è¯•ç»“æœ
        factory_tests = ['model_factory', 'data_factory', 'task_factory', 'trainer_factory']
        factory_passed = sum(1 for test in factory_tests if test_results.get(test, False))
        factory_total = len(factory_tests)
        print(f"å·¥å‚æµ‹è¯•: {factory_passed}/{factory_total} é€šè¿‡")

        # æ¨¡å‹æµ‹è¯•ç»“æœ
        model_categories = ['isfm', 'cnn', 'rnn', 'transformer', 'mlp']
        total_models = 0
        passed_models = 0

        for category in model_categories:
            results = test_results.get(f'models_{category}', [])
            if results:
                total_models += len(results)
                passed = sum(1 for r in results if r['status'] == 'passed')
                passed_models += passed

        print(f"æ¨¡å‹æµ‹è¯•: {passed_models}/{total_models} é€šè¿‡")

        print(f"\næ€»è€—æ—¶: {elapsed:.2f}ç§’")

        if factory_passed == factory_total and passed_models == total_models:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("PHM-Vibenchæ¨¡å—åŠŸèƒ½å®Œå…¨æ­£å¸¸ã€‚")
        elif factory_passed == factory_total:
            print("\nâœ… å·¥å‚æ¨¡å¼æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
            print("âš ï¸ éƒ¨åˆ†æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚")
        else:
            print(f"\nâš ï¸ {factory_total - factory_passed}ä¸ªå·¥å‚æµ‹è¯•å¤±è´¥ã€‚")

        if passed_models < total_models:
            print("\nğŸ’¡ æ¨¡å‹æµ‹è¯•å¤±è´¥çš„ä¸»è¦åŸå› :")
            print("   - é…ç½®å‚æ•°ä¸åŒ¹é…æ¨¡å‹æœŸæœ›")
            print("   - æŸäº›æ¨¡å‹éœ€è¦é¢å¤–çš„é…ç½®å‚æ•°")
            print("   - å»ºè®®æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯å¹¶è°ƒæ•´é…ç½®")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PHM-Vibenchå…¨é¢æ¨¡å—æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼šä»…æµ‹è¯•åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­')
    parser.add_argument('--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯')
    parser.add_argument('--category', choices=['isfm', 'cnn', 'rnn', 'transformer', 'mlp', 'all'],
                       default='all', help='æµ‹è¯•ç‰¹å®šç±»åˆ«çš„æ¨¡å‹')

    args = parser.parse_args()

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ModuleTester(quick_mode=args.quick, verbose=args.verbose)

    # è¿è¡Œæµ‹è¯•
    if args.category == 'all':
        results = tester.run_all_tests()
    else:
        # è¿è¡Œç‰¹å®šç±»åˆ«æµ‹è¯•
        configs = tester._get_model_configs()
        if args.category in configs:
            print(f"æµ‹è¯• {args.category.upper()} ç±»åˆ«æ¨¡å‹...")
            results = tester._test_model_category(configs[args.category], args.category)
            print(f"\nç»“æœ: {sum(1 for r in results if r['status'] == 'passed')}/{len(results)} é€šè¿‡")
        else:
            print(f"æœªçŸ¥ç±»åˆ«: {args.category}")

    return 0 if all(r['status'] == 'passed' for r in results) else 1


if __name__ == "__main__":
    sys.exit(main())